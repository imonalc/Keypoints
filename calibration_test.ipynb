{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg2png(path):\n",
    "    jpg_file = f\"{path}.jpg\"\n",
    "    png_file = f\"{path}.png\"\n",
    "    image = Image.open(jpg_file)\n",
    "    image.save(png_file, \"PNG\")\n",
    "\n",
    "    print(\"変換完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_o = \"data/example/room2/O\"\n",
    "path_r = \"data/example/room2/R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "変換完了\n",
      "変換完了\n"
     ]
    }
   ],
   "source": [
    "jpg2png(path_o)\n",
    "jpg2png(path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input_path, output_path, new_size):\n",
    "    # 画像を開く\n",
    "    with Image.open(input_path) as img:\n",
    "        # 画像をリサイズ\n",
    "        resized_img = img.resize(new_size)\n",
    "        \n",
    "        # リサイズした画像を保存\n",
    "        resized_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (4096, 2048)\n",
    "resize_image(f\"{path_o}.png\", f\"{path_o[:-1]}4096/O.png\", size)\n",
    "resize_image(f\"{path_r}.png\", f\"{path_r[:-1]}4096/R.png\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (2048, 1024)\n",
    "resize_image(f\"{path_o}.png\", f\"{path_o[:-1]}2048/O.png\", size)\n",
    "resize_image(f\"{path_r}.png\", f\"{path_r[:-1]}2048/R.png\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (1024, 512)\n",
    "resize_image(f\"{path_o}.png\", f\"{path_o[:-1]}1024/O.png\", size)\n",
    "resize_image(f\"{path_r}.png\", f\"{path_r[:-1]}1024/R.png\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (512, 256)\n",
    "resize_image(f\"{path_o}.png\", f\"{path_o[:-1]}512/O.png\", size)\n",
    "resize_image(f\"{path_r}.png\", f\"{path_r[:-1]}512/R.png\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_at(video_path, frame_number):\n",
    "    \"\"\"\n",
    "    特定のフレーム番号でビデオのフレームを表示します。\n",
    "    :param video_path: ビデオファイルへのパス\n",
    "    :param frame_number: 表示するフレームの番号\n",
    "    \"\"\"\n",
    "    # 動画ファイルを開く\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 特定のフレームに移動\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    \n",
    "    # フレームを読み込む\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"フレームが見つかりません。\")\n",
    "        video_capture.release()\n",
    "        return\n",
    "    \n",
    "    # フレームを表示\n",
    "    resized_frame = cv2.resize(frame, (1024, 512))\n",
    "    cv2.imshow(\"Frame\", resized_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # メモリを解放し、ファイルを閉じる\n",
    "    video_capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"Calibration\"\n",
    "pose = \"pose_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number_o = 61  # 表示したいフレーム番号 182\n",
    "video_path = f\"./data/data_real/{scene}/{pose}/O_raw.mp4\"\n",
    "show_frame_at(video_path, frame_number_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number_r = 59  # 表示したいフレーム番号 271\n",
    "video_path = f\"./data/data_real/{scene}/{pose}/R_raw.mp4\"\n",
    "show_frame_at(video_path, frame_number_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame(video_path, output_path, frame_number):\n",
    "    # 動画を読み込む\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # 動画のフレーム数を取得\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # 指定されたフレーム番号が動画のフレーム数を超えていないかチェック\n",
    "    if frame_number >= total_frames:\n",
    "        print(\"指定されたフレーム番号は動画のフレーム数を超えています。\")\n",
    "        cap.release()\n",
    "        return\n",
    "    \n",
    "    # 指定されたフレーム番号にセット\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    \n",
    "    # フレームを読み込む\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # 読み込みに成功した場合、画像を保存\n",
    "    if ret:\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        print(\"画像を保存しました。\")\n",
    "    else:\n",
    "        print(\"指定されたフレームの読み込みに失敗しました。\")\n",
    "    \n",
    "    # キャプチャをリリース\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像を保存しました。\n",
      "画像を保存しました。\n"
     ]
    }
   ],
   "source": [
    "output_path_o =  \"./data/example/room2/O.png\"\n",
    "output_path_r =  \"./data/example/room2/R.png\"\n",
    "extract_frame(video_path, output_path_o, frame_number_o)\n",
    "extract_frame(video_path, output_path_r, frame_number_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def trim_video(video_path, output_path, start_frame):\n",
    "    \"\"\"\n",
    "    指定されたフレームから動画をトリミングして、新しいファイルとして保存する関数。\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): 入力動画のファイルパス。\n",
    "    output_path (str): トリミングされた動画の保存先のファイルパス。\n",
    "    start_frame (int): トリミングを開始するフレーム番号。\n",
    "    \"\"\"\n",
    "    # VideoFileClipオブジェクトを作成して動画を読み込む\n",
    "    clip = VideoFileClip(video_path)\n",
    "\n",
    "    fps = clip.fps\n",
    "\n",
    "    # フレームレートがNoneの場合、デフォルト値を設定\n",
    "    if fps is None:\n",
    "        fps = 30  # 一般的なフレームレート\n",
    "\n",
    "    # 開始時間（秒）を計算\n",
    "    start_time = start_frame / fps\n",
    "\n",
    "    # トリミングされたクリップを作成\n",
    "    trimmed_clip = clip.subclip(start_time)\n",
    "\n",
    "    # 新しいファイルとして保存\n",
    "    trimmed_clip.write_videofile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./data/data_real/Calibration/pose_test/O.mp4.\n",
      "MoviePy - Writing audio in OTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./data/data_real/Calibration/pose_test/O.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./data/data_real/Calibration/pose_test/O.mp4\n"
     ]
    }
   ],
   "source": [
    "# 使用例\n",
    "video_path = f\"./data/data_real/{scene}/{pose}/O_raw.mp4\"\n",
    "output_path = f\"./data/data_real/{scene}/{pose}/O.mp4\" # 出力したい動画の保存先パス\n",
    "trim_video(video_path, output_path, frame_number_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./data/data_real/Calibration/pose_test/R.mp4.\n",
      "MoviePy - Writing audio in RTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video ./data/data_real/Calibration/pose_test/R.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./data/data_real/Calibration/pose_test/R.mp4\n"
     ]
    }
   ],
   "source": [
    "# 使用例\n",
    "video_path = f\"./data/data_real/{scene}/{pose}/R_raw.mp4\"\n",
    "output_path = f\"./data/data_real/{scene}/{pose}/R.mp4\" # 出力したい動画の保存先パス\n",
    "trim_video(video_path, output_path, frame_number_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie to images\n",
    "def extract_frames(video_path, output_path, frame_interval, name):\n",
    "    # resolution\n",
    "    resolution = (1024, 512)\n",
    "    # 動画ファイルを開く\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # フレームカウンタを初期化\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # フレームを読み込む\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        # フレームが正常に読み込まれなかった場合、ループを終了\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # フレームカウンタが指定したフレーム間隔の倍数のときに画像を保存\n",
    "        if frame_count % frame_interval == 0:\n",
    "            resized_frame = cv2.resize(frame, resolution)\n",
    "            output_foldername = f\"{output_path}/{frame_count//frame_interval}\"\n",
    "            if not os.path.exists(output_foldername):\n",
    "                os.makedirs(output_foldername)\n",
    "            output_filename = f\"{output_foldername}/{name}.png\"\n",
    "            #cv2.imwrite(output_filename, frame)\n",
    "            cv2.imwrite(output_filename, resized_frame)\n",
    "        \n",
    "        # フレームカウンタをインクリメント\n",
    "        if frame_count // frame_interval >=99:\n",
    "            break\n",
    "        frame_count += 1\n",
    "    # メモリを解放し、ファイルを閉じる\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f\"./data/data_real/{scene}/{pose}/O.mp4\"\n",
    "output_path = f\"./data/data_real/{scene}/{pose}\"    # 出力画像の保存先ディレクトリパス\n",
    "frame_interval = 5\n",
    "extract_frames(video_path, output_path, frame_interval, \"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f\"./data/data_real/{scene}/{pose}/R.mp4\"\n",
    "output_path = f\"./data/data_real/{scene}/{pose}\"    # 出力画像の保存先ディレクトリパス\n",
    "frame_interval = 5\n",
    "extract_frames(video_path, output_path, frame_interval, \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75704225  0.48070549 -0.4425034 ]\n",
      " [-0.08842974  0.74642044  0.65957313]\n",
      " [ 0.64735401 -0.46019426  0.60758047]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 'R.npy'ファイルを読み込む\n",
    "data = np.load('./data/data_100/Classroom/0/R.npy')\n",
    "\n",
    "# 読み込んだデータを表示する\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kalibr output to npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_rotation_matrix(q):\n",
    "    # Normalize quaternion\n",
    "    q = q / np.linalg.norm(q)\n",
    "    a, b, c, d = q\n",
    "    R = np.array([\n",
    "        [1 - 2*c**2 - 2*d**2, 2*b*c - 2*a*d, 2*b*d + 2*a*c],\n",
    "        [2*b*c + 2*a*d, 1 - 2*b**2 - 2*d**2, 2*c*d - 2*a*b],\n",
    "        [2*b*d - 2*a*c, 2*c*d + 2*a*b, 1 - 2*b**2 - 2*c**2]\n",
    "    ])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [-0.32801302, -0.33896052, 0.10159295, 0.87589503] \n",
    "t = [ 0.27359878, 0.0336999, -0.35338568]\n",
    "q = [-q[3], q[2], q[0], q[1]]\n",
    "t = [-t[2], -t[0], -t[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55502645 -0.66043529  0.50573795]\n",
      " [ 0.52714005  0.74956928  0.40033645]\n",
      " [-0.64348194  0.04439741  0.76417266]]\n",
      "[ 0.78847462 -0.61045397 -0.07519126]\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./data/data_real/\"\n",
    "R = quaternion_to_rotation_matrix(q)\n",
    "T = t/np.linalg.norm(t)\n",
    "print(R)\n",
    "print(T)\n",
    "np.save(f'{base_path}R.npy', R)\n",
    "np.save(f'{base_path}T.npy', T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [ 0.05933311, -0.07535888, 0.00028453, 0.99538964] \n",
    "t = [ 0.43209423, -0.00641689, -0.0104084 ] \n",
    "q = [-q[3], q[2], q[0], q[1]]\n",
    "t = [-t[2], -t[0], -t[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98160124 -0.14998913 -0.11816201]\n",
      " [ 0.15005666  0.98864192 -0.00837612]\n",
      " [ 0.11807624 -0.00950899  0.992959  ]]\n",
      "[ 0.02407863 -0.99959985  0.01484473]\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./data/data_real/\"\n",
    "R = quaternion_to_rotation_matrix(q)\n",
    "T = t/np.linalg.norm(t)\n",
    "print(R)\n",
    "print(T)\n",
    "np.save(f'{base_path}R.npy', R)\n",
    "np.save(f'{base_path}T.npy', T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
