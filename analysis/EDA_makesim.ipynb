{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imonalc/anaconda3/envs/keypoints/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+'/fivepoint')\n",
    "import build.fivep as f\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from spherical_distortion.functional import create_tangent_images, unresample\n",
    "from spherical_distortion.util import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _spherical_distortion_ext._mesh as _mesh\n",
    "import argparse\n",
    "\n",
    "from random import sample\n",
    "import imageio\n",
    "from scipy.spatial.transform import Rotation as Rot\n",
    "\n",
    "from utils.coord    import coord_3d\n",
    "from utils.ransac   import *\n",
    "from utils.keypoint import *\n",
    "from utils.metrics  import *\n",
    "from utils.camera_recovering import *\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.getcwd()+'/SPHORB-master')\n",
    "\n",
    "import build1.sphorb_cpp as sphorb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(pts1, pts2, desc1, desc2, points):\n",
    "\n",
    "    ind1 = np.argsort(pts1[:,2].numpy(),axis = 0)[::-1]\n",
    "    ind2 = np.argsort(pts2[:,2].numpy(),axis = 0)[::-1]\n",
    "\n",
    "    max1 = np.min([points,ind1.shape[0]])\n",
    "    max2 = np.min([points,ind2.shape[0]])\n",
    "\n",
    "    ind1 = ind1[:max1]\n",
    "    ind2 = ind2[:max2]\n",
    "\n",
    "    pts1 = pts1[ind1.copy(),:]\n",
    "    pts2 = pts2[ind2.copy(),:]\n",
    "\n",
    "    desc1 = desc1[:,ind1.copy()]\n",
    "    desc2 = desc2[:,ind2.copy()]\n",
    "\n",
    "    pts1 = np.concatenate((pts1[:,:2], np.ones((pts1.shape[0],1))), axis = 1 )\n",
    "    pts2 = np.concatenate((pts2[:,:2], np.ones((pts2.shape[0],1))), axis = 1 )\n",
    "\n",
    "    desc1 = np.transpose(desc1,[1,0]).numpy()\n",
    "    desc2 = np.transpose(desc2,[1,0]).numpy()\n",
    "\n",
    "    return pts1, pts2, desc1, desc2\n",
    "\n",
    "\n",
    "def mnn_matcher(desc1, desc2, method=\"mean_std\"):\n",
    "    sim = desc1 @ desc2.transpose()\n",
    "    if method == \"mean_std\":\n",
    "        k = 4\n",
    "        threshold = sim.mean() + k * sim.std()\n",
    "    sim_raw = sim.copy()\n",
    "    sim[sim < threshold] = 0\n",
    "    nn12 = np.argmax(sim, axis=1)\n",
    "    nn21 = np.argmax(sim, axis=0)\n",
    "    ids1 = np.arange(0, sim.shape[0])\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = np.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.transpose(), sim_raw\n",
    "\n",
    "\n",
    "def euclid_matcher(desc1, desc2, method=\"mean_std\"):\n",
    "    dists = np.sum((desc1[:, np.newaxis] - desc2)**2, axis=2)\n",
    "\n",
    "    if method == \"mean_std\":\n",
    "        k = 4\n",
    "        threshold = dists.mean() + k * dists.std()\n",
    "    \n",
    "    dists_raw = dists.copy()\n",
    "    dists[dists > threshold] = np.inf\n",
    "    nn12 = np.argmin(dists, axis=1)\n",
    "    nn21 = np.argmin(dists, axis=0)\n",
    "    ids1 = np.arange(0, dists.shape[0])\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = np.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.transpose(), dists_raw\n",
    "\n",
    "\n",
    "def matched_points(pts1, pts2, desc1, desc2, opt, args_opt, match='ratio', use_new_method=0):\n",
    "    if opt[-1] == 'p':\n",
    "        porce = int(opt[:-1])\n",
    "        n_key = int(porce/100 * pts1.shape[0])\n",
    "    else:\n",
    "        n_key = int(opt)\n",
    "\n",
    "    s_pts1  = pts1.copy()[:n_key,:]\n",
    "    s_pts2  = pts2.copy()[:n_key,:]\n",
    "    s_desc1 = desc1.copy().astype('float32')[:n_key,:]\n",
    "    s_desc2 = desc2.copy().astype('float32')[:n_key,:]\n",
    "\n",
    "    if 'orb' in args_opt:\n",
    "        s_desc1 = s_desc1.astype(np.uint8)\n",
    "        s_desc2 = s_desc2.astype(np.uint8)\n",
    "        hamming_distances = np.array([[cv2.norm(d1, d2, cv2.NORM_HAMMING) for d2 in s_desc2] for d1 in s_desc1])\n",
    "        sim = -hamming_distances\n",
    "        nn12 = np.argmin(hamming_distances, axis=1)\n",
    "        nn21 = np.argmin(hamming_distances, axis=0)\n",
    "        ids1 = np.arange(len(s_desc1))\n",
    "        mask = (ids1 == nn21[nn12])\n",
    "        matches = [cv2.DMatch(i, j, 0) for i, j in zip(ids1[mask], nn12[mask])]\n",
    "    elif \"superpoint\" in args_opt:\n",
    "        matches_idx, sim = mnn_matcher(s_desc1, s_desc2)\n",
    "        matches = [cv2.DMatch(i, j, 0) for i, j in matches_idx]\n",
    "    elif \"sift\" in args_opt:\n",
    "        matches_idx, sim = euclid_matcher(s_desc1, s_desc2)\n",
    "        matches = [cv2.DMatch(i, j, 0) for i, j in matches_idx]\n",
    "\n",
    "\n",
    "    M = np.zeros((2,len(matches)))\n",
    "    for ind, match in zip(np.arange(len(matches)),matches):\n",
    "        M[0,ind] = match.queryIdx\n",
    "        M[1,ind] = match.trainIdx\n",
    "\n",
    "\n",
    "    return s_pts1, s_pts2, s_pts1[M[0,:].astype(int),:3], s_pts2[M[1,:].astype(int),:3], sim\n",
    "\n",
    "\n",
    "def get_error(x1, x2, Rx, Tx):\n",
    "\n",
    "    S = computeEssentialMatrixByRANSAC(x1, x2)\n",
    "    I = S[1]\n",
    "    I = I.astype(np.int64)\n",
    "\n",
    "    x1 = x1[I,:]\n",
    "    x2 = x2[I,:]\n",
    "\n",
    "    F = calc_ematrix(x1,x2)\n",
    "\n",
    "\n",
    "    R1,R2,T1,T2 = decomposeE(F)\n",
    "\n",
    "    R,T = choose_rt(R1,R2,T1,T2,x1,x2)\n",
    "\n",
    "    R_error = r_error(Rx,R)\n",
    "    T_error = t_error(Tx,T)\n",
    "\n",
    "    return R_error, T_error\n",
    "\n",
    "\n",
    "def get_descriptor(descriptor):\n",
    "    if descriptor == 'sphorb':\n",
    "        return 'sphorb', 'erp', 640, 0\n",
    "    elif descriptor == 'sift':\n",
    "        return 'sift', 'erp', 512, 0\n",
    "    elif descriptor == 'tsift':\n",
    "        return 'sift', 'tangent', 512, 0\n",
    "    elif descriptor == 'orb':\n",
    "        return 'orb', 'erp', 512, 0\n",
    "    elif descriptor == 'torb':\n",
    "        return 'orb', 'tangent', 512, 0\n",
    "    elif descriptor == 'spoint':\n",
    "        return 'superpoint', 'erp', 512, 0\n",
    "    elif descriptor == 'tspoint':\n",
    "        return 'superpoint', 'tangent', 512, 0\n",
    "    elif descriptor == 'alike':\n",
    "        return 'alike', 'erp', 512, 0\n",
    "    elif descriptor == 'talike':\n",
    "        return 'alike', 'tangent', 512, 0\n",
    "    elif descriptor == 'Proposed':\n",
    "        return 'superpoint', 'tangent', 512, 1\n",
    "    elif descriptor == 'Ltspoint':\n",
    "        return 'superpoint', 'tangent', 512, 2\n",
    "    elif descriptor == 'Ftspoint':\n",
    "        return 'superpoint', 'tangent', 512, 3\n",
    "\n",
    "\n",
    "def get_error(x1, x2, Rx, Tx):\n",
    "\n",
    "    S = computeEssentialMatrixByRANSAC(x1, x2)\n",
    "    I = S[1]\n",
    "    I = I.astype(np.int64)\n",
    "\n",
    "    x1 = x1[I,:]\n",
    "    x2 = x2[I,:]\n",
    "\n",
    "    F = calc_ematrix(x1,x2)\n",
    "\n",
    "\n",
    "    R1,R2,T1,T2 = decomposeE(F)\n",
    "\n",
    "    R,T = choose_rt(R1,R2,T1,T2,x1,x2)\n",
    "\n",
    "    R_error = r_error(Rx,R)\n",
    "    T_error = t_error(Tx,T)\n",
    "\n",
    "    return R_error, T_error\n",
    "\n",
    "\n",
    "def AUC(ROT, TRA, MET, L):\n",
    "\n",
    "    RAUC  = np.zeros(len(L))\n",
    "    TAUC  = np.zeros(len(L))\n",
    "\n",
    "    for index, t in enumerate(L):\n",
    "        ids = np.where(ROT<np.radians(t))[0]\n",
    "        RAUC[index] = len(ids)/len(ROT)\n",
    "\n",
    "    for index, t in enumerate(L):\n",
    "        ids = np.where(TRA<np.radians(t))[0]\n",
    "        TAUC[index] = len(ids)/len(TRA)\n",
    "\n",
    "    return RAUC, TAUC, np.array(MET)\n",
    "\n",
    "\n",
    "def get_data(DATAS):\n",
    "    if len(DATAS) == 1:\n",
    "        data = DATAS[0]\n",
    "    elif set(['Urban1','Urban2','Urban3','Urban4']) == set(DATAS):\n",
    "        data = 'Outdoor'\n",
    "    elif set(['Realistic','Interior1','Interior2','Room','Classroom']) == set(DATAS):\n",
    "        data = 'Indoor'\n",
    "    elif set(['Urban1_R','Urban2_R','Urban3_R','Urban4_R','Realistic_R','Interior1_R','Interior2_R','Room_R','Classroom_R']) == set(DATAS):\n",
    "        data = 'OnlyRot'\n",
    "    elif set(['Urban1_T','Urban2_T','Urban3_T','Urban4_T','Realistic_T','Interior1_T','Interior2_T','Room_T','Classroom_T']) == set(DATAS):\n",
    "        data = 'OnlyTra'\n",
    "    else:\n",
    "        data = ''\n",
    "        for DA in DATAS:\n",
    "            data+=DA\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_kd(array):\n",
    "\n",
    "    array = np.array(array)\n",
    "    delimiter = int(array[-1])\n",
    "    A = array[:-1]\n",
    "    K = A[:delimiter].reshape(-1,3)\n",
    "    D = A[delimiter:].reshape(-1,32)\n",
    "    return K,D\n",
    "\n",
    "\n",
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis=1, keepdims=True)\n",
    "    normalized_features = features / norms\n",
    "\n",
    "    threshold = 0.2\n",
    "    normalized_features = np.minimum(normalized_features, threshold)\n",
    "\n",
    "    norms = np.linalg.norm(normalized_features, axis=1, keepdims=True)\n",
    "    normalized_features /= norms\n",
    "\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(points = 500,\n",
    "match = \"ratio\",\n",
    "descriptor = \"tsift\",\n",
    "path = \"./data/Farm_pair\",):\n",
    "    t0 = time.time()\n",
    "    descriptor = descriptor\n",
    "\n",
    "    opt, mode, sphered, use_our_method = get_descriptor(descriptor)\n",
    "    base_order = 0  # Base sphere resolution\n",
    "    sample_order = 8  # Determines sample resolution (10 = 2048 x 4096)\n",
    "    scale_factor = 1.0  # How much to scale input equirectangular image by\n",
    "    save_ply = False  # Whether to save the PLY visualizations too\n",
    "    dim = np.array([2*sphered, sphered])\n",
    "\n",
    "    path_o = path + '/O.png'\n",
    "    path_r = path + '/R.png'\n",
    "    img_o = load_torch_img(path_o)[:3, ...].float()\n",
    "    img_o = F.interpolate(img_o.unsqueeze(0), scale_factor=scale_factor, mode='bilinear', align_corners=False, recompute_scale_factor=True).squeeze(0)\n",
    "    img_r = load_torch_img(path_r)[:3, ...].float()\n",
    "    img_r = F.interpolate(img_r.unsqueeze(0), scale_factor=scale_factor, mode='bilinear', align_corners=False, recompute_scale_factor=True).squeeze(0)\n",
    "    img_o = torch2numpy(img_o.byte())\n",
    "    img_r = torch2numpy(img_r.byte())\n",
    "    img_o = cv2.cvtColor(img_o, cv2.COLOR_BGR2RGB)\n",
    "    img_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2RGB)\n",
    "    height_threshold = 0.7 * img_o.shape[0]\n",
    "\n",
    "\n",
    "    print(path_o)\n",
    "    t1 = time.time()\n",
    "    print(\"image:\", t1-t0)\n",
    "    if opt != 'sphorb':\n",
    "        corners = tangent_image_corners(base_order, sample_order)\n",
    "        pts1, desc1 = process_image_to_keypoints(path_o, corners, scale_factor, base_order, sample_order, opt, mode)\n",
    "        print(descriptor, len(pts1))\n",
    "        pts2, desc2 = process_image_to_keypoints(path_r, corners, scale_factor, base_order, sample_order, opt, mode)\n",
    "        pts1[pts1[:,0] > img_o.shape[1], 0] -= img_o.shape[1]\n",
    "        pts2[pts2[:,0] > img_o.shape[1], 0] -= img_o.shape[1]\n",
    "    else:      \n",
    "        os.chdir('SPHORB-master/')\n",
    "        pts1, desc1 = get_kd(sphorb.sphorb(path_o, points))\n",
    "        pts2, desc2 = get_kd(sphorb.sphorb(path_r, points))\n",
    "        os.chdir('../')\n",
    "    #if opt == \"sift\":\n",
    "    #    desc1 = normalize_features(desc1)\n",
    "    #    desc2 = normalize_features(desc2)\n",
    "\n",
    "    #print(desc1.shape, desc1)\n",
    "    pts1, pts2, desc1, desc2, _, _ = sort_key(pts1, pts2, desc1, desc2, points)\n",
    "    t2 = time.time()\n",
    "    print(\"detection:\", t2-t1)\n",
    "    if len(pts1.shape) == 1:\n",
    "        pts1 = pts1.reshape(1,-1)\n",
    "\n",
    "    print(desc1.shape)\n",
    "    s_pts1, s_pts2, x1, x2, sim = matched_points(pts1, pts2, desc1, desc2, \"100p\", opt, match, use_new_method=use_our_method)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Farm_pair/O.png\n",
      "image: 0.12318563461303711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imonalc/anaconda3/envs/keypoints/lib/python3.7/site-packages/torch/nn/functional.py:4228: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed 520\n",
      "detection: 1.9257798194885254\n",
      "(500, 256)\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.1635584831237793\n",
      "orb 9263\n",
      "detection: 0.41322803497314453\n",
      "(500, 32)\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.03667473793029785\n",
      "torb 10480\n",
      "detection: 0.4716174602508545\n",
      "(500, 32)\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.03555583953857422\n",
      "sift 3241\n",
      "detection: 0.5002164840698242\n",
      "(500, 128)\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.0409855842590332\n",
      "tsift 1859\n",
      "detection: 2.404430389404297\n",
      "(500, 128)\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.03394937515258789\n",
      "spoint 1013\n",
      "detection: 0.4361600875854492\n",
      "(500, 256)\n"
     ]
    }
   ],
   "source": [
    "sim_p = test(descriptor=\"Proposed\")\n",
    "sim_o = test(descriptor=\"orb\")\n",
    "sim_to = test(descriptor=\"torb\")\n",
    "sim_s = test(descriptor=\"sift\")\n",
    "sim_ts = test(descriptor=\"tsift\")\n",
    "sim_sp = test(descriptor=\"spoint\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dict = {\n",
    "    \"spoint\": sim_sp,\n",
    "    \"tspoint\": sim_p,\n",
    "    \"orb\": sim_o,\n",
    "    \"torb\": sim_to,\n",
    "    \"sift\": sim_s,\n",
    "    \"tsift\": sim_ts \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"sim.pickle\", mode='wb') as f:\n",
    "    pickle.dump(sim_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
