{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "OUTPUT_DIR = \"./output/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_theta_torch(x, y):\n",
    "    theta = torch.where(y < 0, (-1) * torch.atan2(y, x), 2 * math.pi - torch.atan2(y, x))\n",
    "    return theta\n",
    "\n",
    "def create_equirectangular_to_bottom_and_top_map(input_w, input_h, output_sqr, z):\n",
    "    x, y = torch.meshgrid(torch.linspace(-output_sqr, output_sqr-1, output_sqr), \n",
    "                          torch.linspace(-output_sqr, output_sqr-1, output_sqr),indexing='ij')\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    z = torch.tensor(z).to(device)\n",
    "    \n",
    "    rho = torch.sqrt(x**2 + y**2 + z**2)\n",
    "    norm_theta = get_theta_torch(x, y) / (2 * math.pi)\n",
    "    norm_phi = (math.pi - torch.acos(z / rho)) / math.pi\n",
    "    ix = norm_theta * input_w\n",
    "    iy = norm_phi * input_h\n",
    "\n",
    "    ix = torch.remainder(ix, input_w)\n",
    "    iy = torch.remainder(iy, input_h)\n",
    "    \n",
    "    return ix.cpu().numpy(), iy.cpu().numpy()\n",
    "\n",
    "\n",
    "def create_equirectangular_to_front_and_back_map(input_w, input_h, output_sqr, x):\n",
    "    z, y = torch.meshgrid(torch.linspace(-output_sqr, output_sqr-1, output_sqr), \n",
    "                          torch.linspace(-output_sqr, output_sqr-1, output_sqr),indexing='ij')\n",
    "    z, y = z.to(device), y.to(device)\n",
    "    x = torch.tensor(x).to(device)\n",
    "    \n",
    "    rho = torch.sqrt(x**2 + y**2 + z**2)\n",
    "    norm_theta = get_theta_torch(x, y) / (2 * math.pi)\n",
    "    norm_phi = (math.pi - torch.acos(z / rho)) / math.pi\n",
    "    ix = norm_theta * input_w\n",
    "    iy = norm_phi * input_h\n",
    "\n",
    "    ix = torch.remainder(ix, input_w)\n",
    "    iy = torch.remainder(iy, input_h)\n",
    "    \n",
    "    return ix.cpu().numpy(), iy.cpu().numpy()\n",
    "\n",
    "\n",
    "def create_equirectangular_to_left_and_right_map(input_w, input_h, output_sqr, y):\n",
    "    x, z = torch.meshgrid(torch.linspace(-output_sqr, output_sqr-1, output_sqr), \n",
    "                          torch.linspace(-output_sqr, output_sqr-1, output_sqr),indexing='ij')\n",
    "    x, z = x.to(device), z.to(device)\n",
    "    y = torch.tensor(y).to(device)\n",
    "    \n",
    "    rho = torch.sqrt(x**2 + y**2 + z**2)\n",
    "    norm_theta = get_theta_torch(x, y) / (2 * math.pi)\n",
    "    norm_phi = (math.pi - torch.acos(z / rho)) / math.pi\n",
    "    ix = norm_theta * input_w\n",
    "    iy = norm_phi * input_h\n",
    "\n",
    "    ix = torch.remainder(ix, input_w)\n",
    "    iy = torch.remainder(iy, input_h)\n",
    "    \n",
    "    return ix.cpu().numpy(), iy.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "def create_cube_imgs_pad(img, margin=10):\n",
    "    input_h, input_w, _ = img.shape\n",
    "    output_sqr = int(input_w / 4)\n",
    "    normalized_f = 1\n",
    "\n",
    "    z = (output_sqr / normalized_f)\n",
    "    bottom_map_x, bottom_map_y = create_equirectangular_to_bottom_and_top_map(input_w, input_h, output_sqr+margin*2, z)\n",
    "    bottom_img = cv2.remap(img, bottom_map_x.astype(\"float32\"), bottom_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "\n",
    "    z = (-1) * (output_sqr / normalized_f)\n",
    "    top_map_x, top_map_y = create_equirectangular_to_bottom_and_top_map(input_w, input_h, output_sqr+margin*2, z)\n",
    "    top_img = cv2.remap(img, top_map_x.astype(\"float32\"), top_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "    top_img = cv2.flip(top_img, 0)\n",
    "\n",
    "    x = (-1) * (output_sqr / normalized_f)\n",
    "    front_map_x, front_map_y = create_equirectangular_to_front_and_back_map(input_w, input_h, output_sqr+margin*2, x)\n",
    "    front_img = cv2.remap(img, front_map_x.astype(\"float32\"), front_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "\n",
    "    x = output_sqr / normalized_f\n",
    "    back_map_x, back_map_y = create_equirectangular_to_front_and_back_map(input_w, input_h, output_sqr+margin*2, x)\n",
    "    back_img = cv2.remap(img, back_map_x.astype(\"float32\"), back_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "    back_img = cv2.flip(back_img, 1)\n",
    "\n",
    "    y = (-1) * (output_sqr / normalized_f)\n",
    "    left_map_x, left_map_y = create_equirectangular_to_left_and_right_map(input_w, input_h, output_sqr+margin*2, y)\n",
    "    left_img = cv2.remap(img, left_map_x.astype(\"float32\"), left_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "    left_img = cv2.rotate(left_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    y = output_sqr / normalized_f\n",
    "    right_map_x, right_map_y = create_equirectangular_to_left_and_right_map(input_w, input_h, output_sqr+margin*2, y)\n",
    "    right_img = cv2.remap(img, right_map_x.astype(\"float32\"), right_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "    right_img = cv2.flip(right_img, 1)\n",
    "    right_img = cv2.rotate(right_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    return [back_img, bottom_img, front_img, left_img, right_img, top_img], output_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cube_map(back_img, bottom_img, front_img, left_img, right_img, top_img, output_sqr):\n",
    "    cube_map_img = np.zeros((3 * output_sqr, 4 * output_sqr, 3))\n",
    "    cube_map_img[output_sqr:2*output_sqr, 3*output_sqr:4*output_sqr] = back_img\n",
    "    cube_map_img[2*output_sqr:3*output_sqr, output_sqr:2*output_sqr] = bottom_img\n",
    "    cube_map_img[output_sqr:2*output_sqr, output_sqr:2*output_sqr] = front_img\n",
    "    cube_map_img[output_sqr:2*output_sqr, 0:output_sqr] = left_img\n",
    "    cube_map_img[output_sqr:2*output_sqr, 2*output_sqr:3*output_sqr] = right_img\n",
    "    cube_map_img[0:output_sqr, output_sqr:2*output_sqr] = top_img\n",
    "    return cube_map_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1024, 3) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"../data/example/farm4/O.png\"\n",
    "img = cv2.imread(image_path)\n",
    "print(img.shape, type(img))\n",
    "[back_img, bottom_img, front_img, left_img, right_img, top_img], output_sqr = create_cube_imgs_pad(img, margin=0)\n",
    "cube_map_img = create_cube_map(back_img, bottom_img, front_img, left_img, right_img, top_img, output_sqr)\n",
    "\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}bottom.png\", bottom_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}top.png\", top_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}front.png\", front_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}back.png\", back_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}left.png\", left_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}right.png\", right_img)\n",
    "cv2.imwrite(f\"{OUTPUT_DIR}cube_map.png\", cube_map_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1745.748779296875, 749.854248046875)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def cube_coord_to_3d_vector(face: str, cor_xy: (float, float), width: int) -> torch.Tensor:\n",
    "    x, y = cor_xy\n",
    "    x -= width\n",
    "    y -= width\n",
    "\n",
    "    \n",
    "    # Depending on the face, compute the 3D direction\n",
    "    if face == \"front\":\n",
    "        return torch.tensor([width, y, -x])#torch.tensor([x, y, width/2])\n",
    "    elif face == \"back\":\n",
    "        return torch.tensor([-width, -y, -x])\n",
    "    elif face == \"right\":\n",
    "        return torch.tensor([-y, width, -x])#torch.tensor([x, width/2, y])\n",
    "    elif face == \"left\":\n",
    "        return torch.tensor([y, -width, -x])#torch.tensor([width/2, y, x])\n",
    "    elif face == \"top\":\n",
    "        return torch.tensor([x, y, width])#torch.tensor([x, y, width/2])#torch.tensor([x, y, -width/2]) # ok\n",
    "    elif face == \"bottom\":\n",
    "        return torch.tensor([-x, y, -width])#torch.tensor([x, y, -width/2])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid face name: {face}\")\n",
    "    \n",
    "def vector_to_equirectangular_coord(vec: torch.Tensor, width: int) -> (float, float):\n",
    "    # Convert 3D cartesian coordinates to spherical coordinates\n",
    "    r = torch.sqrt(torch.sum(vec**2))\n",
    "    theta = torch.acos(vec[2] / r)  # polar angle (0 <= theta <= pi)\n",
    "    phi = torch.atan2(vec[1], vec[0])  # azimuthal angle (-pi <= phi <= pi)\n",
    "    \n",
    "    # Convert spherical coordinates to 2D equirectangular coordinates\n",
    "    # Taking into account the new desired width and height\n",
    "    x = width * 8 * (phi + torch.pi) / (2 * torch.pi)\n",
    "    y = width * 4 * theta / torch.pi\n",
    "    \n",
    "    return x.item(), y.item()\n",
    "\n",
    "def cube_to_equirectangular_coord(face: str, cor_xy: (float, float), width: int) -> (float, float):\n",
    "    vec = cube_coord_to_3d_vector(face, cor_xy, width)\n",
    "    #print(vector_to_equirectangular_coord(vec, width))\n",
    "    return vector_to_equirectangular_coord(vec, width)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the function\n",
    "    test_face = \"front\"\n",
    "    test_cor_xy = (256, 256)\n",
    "    test_width = 512\n",
    "\n",
    "    print(cube_to_equirectangular_coord(test_face, test_cor_xy, test_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kornia.feature import LoFTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://cmp.felk.cvut.cz/~mishkdmy/models/loftr_outdoor.ckpt\" to /home/imonalc/.cache/torch/hub/checkpoints/loftr_outdoor.ckpt\n",
      "100%|██████████| 44.2M/44.2M [04:58<00:00, 155kB/s] \n"
     ]
    }
   ],
   "source": [
    "matcher = LoFTR(pretrained='outdoor')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
