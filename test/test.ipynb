{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from spherical_distortion.functional import create_tangent_images, unresample\n",
    "from spherical_distortion.util import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import _spherical_distortion_ext._mesh as _mesh\n",
    "import argparse\n",
    "sys.path.append('/home/imonalc/Keypoints/')\n",
    "from utils.eqr2cub import *\n",
    "from utils.cub2eqr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_theta_torch(x, y):\n",
    "    theta = torch.where(y < 0, (-1) * torch.atan2(y, x), 2 * math.pi - torch.atan2(y, x))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_equirectangler_to_bottom_and_top_map(input_w, input_h, output_sqr, z):\n",
    "    x, y = torch.meshgrid(torch.linspace(-output_sqr/2.0, output_sqr/2.0-1, output_sqr), \n",
    "                          torch.linspace(-output_sqr/2.0, output_sqr/2.0-1, output_sqr),indexing='ij')\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    z = torch.tensor(z).to(device)\n",
    "\n",
    "    \n",
    "    rho = torch.sqrt(x**2 + y**2 + z**2)\n",
    "    norm_theta = get_theta_torch(x, y) / (2 * math.pi)\n",
    "    print(norm_theta)\n",
    "    norm_phi = (math.pi - torch.acos(z / rho)) / math.pi\n",
    "\n",
    "    ix = norm_theta * input_w\n",
    "    iy = norm_phi * input_h\n",
    "\n",
    "    # Boundary handling\n",
    "    ix = torch.where(ix >= input_w, ix - input_w, ix)\n",
    "    iy = torch.where(iy >= input_h, iy - input_h, iy)\n",
    "    \n",
    "    return ix.cpu().numpy(), iy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bottom_and_top_to_equirectangular_map(input_w, input_h, output_sqr, iz):\n",
    "    # Create a grid for the bottom map\n",
    "    ix, iy = torch.meshgrid(torch.linspace(-input_h/2, input_h/2-1, input_h),\n",
    "                          torch.linspace(-input_w/2, input_w/2-1, input_w), indexing='ij')\n",
    "    ix, iy = ix.to(device), iy.to(device)\n",
    "    iz = torch.tensor(iz).to(device)\n",
    "    \n",
    "    # Convert the Cartesian coordinates to spherical coordinates\n",
    "    rho = torch.sqrt(ix**2 + iy**2 + iz**2)\n",
    "    theta = get_theta_torch(x, y)\n",
    "    phi = torch.acos(z / rho)\n",
    "    \n",
    "    # Convert the spherical coordinates to equirectangular coordinates\n",
    "    norm_theta = theta / (2 * math.pi)\n",
    "    norm_phi = phi / math.pi\n",
    "    ix = norm_theta * input_w\n",
    "    iy = (1.0 - norm_phi) * input_h  # invert the y-axis since the image coordinate system is top-down\n",
    "    \n",
    "    # Boundary handling\n",
    "    ix = torch.where(ix >= input_w, ix - input_w, ix)\n",
    "    iy = torch.where(iy >= input_h, iy - input_h, iy)\n",
    "    \n",
    "    return ix.cpu().numpy(), iy.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage:\n",
    "top_img = torch.tensor(cv2.imread('output/top.png'))\n",
    "front_img = torch.tensor(cv2.imread('output/front.png'))\n",
    "left_img = torch.tensor(cv2.imread('output/left.png'))\n",
    "right_img = torch.tensor(cv2.imread('output/right.png'))\n",
    "back_img = torch.tensor(cv2.imread('output/back.png'))\n",
    "bottom_img = torch.tensor(cv2.imread('output/bottom.png'))\n",
    "cubemaps = [top_img, front_img, left_img, right_img, back_img, bottom_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"O.jpg\")\n",
    "input_h, input_w, _ = img.shape\n",
    "output_sqr = int(input_w / 4)\n",
    "normalized_f = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[831.3844, 830.8074, 830.2313,  ..., 829.6559, 830.2313, 830.8074],\n",
      "        [830.8074, 830.2301, 829.6536,  ..., 829.0778, 829.6536, 830.2301],\n",
      "        [830.2313, 829.6536, 829.0766,  ..., 828.5004, 829.0766, 829.6536],\n",
      "        ...,\n",
      "        [829.6559, 829.0778, 828.5004,  ..., 827.9239, 828.5004, 829.0778],\n",
      "        [830.2313, 829.6536, 829.0766,  ..., 828.5004, 829.0766, 829.6536],\n",
      "        [830.8074, 830.2301, 829.6536,  ..., 829.0778, 829.6536, 830.2301]],\n",
      "       device='cuda:0') torch.Size([960, 960])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = (output_sqr / (2.0 * normalized_f))\n",
    "bottom_map_x, bottom_map_y = create_equirectangler_to_bottom_and_top_map(input_w, input_h, output_sqr, z)\n",
    "bottom_img = cv2.remap(img, bottom_map_x.astype(\"float32\"), bottom_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "cv2.imwrite(\"aaa.jpg\", bottom_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 960) (960, 960)\n",
      "[[1440.      1440.6373  1441.2759  ... 2398.0842  2398.7239  2399.3625 ]\n",
      " [1439.3625  1440.      1440.6385  ... 2398.7214  2399.3613  2400.     ]\n",
      " [1438.7241  1439.3613  1440.      ... 2399.36    2400.      2400.6387 ]\n",
      " ...\n",
      " [ 481.91586  481.2786   480.63995 ... 3360.      3359.36    3358.7212 ]\n",
      " [ 481.2759   480.63864  480.      ... 3360.64    3360.      3359.361  ]\n",
      " [ 480.63733  480.       479.36133 ... 3361.2786  3360.6387  3360.     ]]\n"
     ]
    }
   ],
   "source": [
    "print(bottom_map_x.shape, bottom_map_y.shape)\n",
    "print(bottom_map_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 663.12555,  663.253  ,  663.3806 , ..., 1384.4916 , 1384.6194 ,\n",
       "         1384.747  ],\n",
       "        [ 662.87085,  662.9981 ,  663.12555, ..., 1384.7467 , 1384.8744 ,\n",
       "         1385.0018 ],\n",
       "        [ 662.6159 ,  662.74304,  662.87036, ..., 1385.002  , 1385.1296 ,\n",
       "         1385.257  ],\n",
       "        ...,\n",
       "        [ 361.63922,  361.51224,  361.38507, ..., 1686.7423 , 1686.6149 ,\n",
       "         1686.4878 ],\n",
       "        [ 361.38406,  361.25696,  361.1296 , ..., 1686.9979 , 1686.8705 ,\n",
       "         1686.7429 ],\n",
       "        [ 361.12912,  361.00186,  360.8744 , ..., 1687.2533 , 1687.1256 ,\n",
       "         1686.9982 ]], dtype=float32),\n",
       " array([[583.70496, 583.75916, 583.81354, ..., 583.8679 , 583.81354,\n",
       "         583.75916],\n",
       "        [583.73206, 583.7864 , 583.8408 , ..., 583.89526, 583.8408 ,\n",
       "         583.7864 ],\n",
       "        [583.7591 , 583.8135 , 583.868  , ..., 583.9225 , 583.868  ,\n",
       "         583.8135 ],\n",
       "        ...,\n",
       "        [583.7862 , 583.84064, 583.89514, ..., 583.9497 , 583.89514,\n",
       "         583.84064],\n",
       "        [583.7591 , 583.8135 , 583.868  , ..., 583.9225 , 583.868  ,\n",
       "         583.8135 ],\n",
       "        [583.73206, 583.7864 , 583.8408 , ..., 583.89526, 583.8408 ,\n",
       "         583.7864 ]], dtype=float32))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the inverse transformation function\n",
    "input_w, input_h, output_sqr = 2048, 1024, 512  # example values\n",
    "z = (output_sqr / (2.0 * 1))  # assuming normalized_f = 1\n",
    "inverse_map_x, inverse_map_y = create_bottom_and_top_to_equirectangular_map(input_w, input_h, output_sqr, z)\n",
    "inverse_map_x, inverse_map_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq_img = np.zeros((3840, 1920, 3))\n",
    "eq_img = cv2.remap(bottom_img, inverse_map_x.astype(\"float32\"), inverse_map_y.astype(\"float32\"), cv2.INTER_CUBIC)\n",
    "cv2.imwrite(\"eq.jpg\", eq_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keyALIKE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
