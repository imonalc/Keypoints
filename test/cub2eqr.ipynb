{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "OUTPUT_DIR = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_img = cv2.imread(\"output/cube_map.png\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3dmap_from_size_torch(img_w, img_h, device):\n",
    "    # np.linspaceをtorch.linspaceに置き換え\n",
    "    h = torch.linspace(-np.pi/2, np.pi/2, img_h, device=device)\n",
    "    w = torch.linspace(-np.pi, np.pi, img_w, device=device)\n",
    "    \n",
    "    # オフセットの追加\n",
    "    h += (np.pi/2) / img_h\n",
    "    w += np.pi / img_w\n",
    "    \n",
    "    # np.meshgridをtorch.meshgridに置き換え\n",
    "    theta, phi = torch.meshgrid(w, h, indexing=\"ij\")\n",
    "    \n",
    "    # 3D座標の計算\n",
    "    x = torch.cos(phi) * torch.cos(theta)\n",
    "    y = torch.cos(phi) * torch.sin(theta)\n",
    "    z = torch.sin(phi)\n",
    "    #print(x, y,z)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_cube(img, device):\n",
    "    # Convert input numpy array to PyTorch tensor\n",
    "    img_tensor = torch.tensor(img).to(device)#.permute(0, 1, pad_w)\n",
    "    \n",
    "    h, w, c = img_tensor.shape\n",
    "    cw = w // 4\n",
    "    #print(h, w, c)\n",
    "\n",
    "    pad_w = 2\n",
    "    \n",
    "    # Initialize canvas tensor\n",
    "    canvas = torch.zeros((h+pad_w*2, w+pad_w*2, c), dtype=img_tensor.dtype, device=device)\n",
    "    canvas[pad_w:-pad_w, pad_w:-pad_w,:] = img_tensor\n",
    "    \n",
    "    # up    \n",
    "    canvas[0:pad_w, cw+pad_w:2*cw+pad_w,:] = torch.rot90(img_tensor[cw:cw+pad_w, 3*cw:,:], 2, [0,1])\n",
    "    # bottom\n",
    "    canvas[-pad_w:, cw+pad_w:2*cw+pad_w,:] = torch.rot90(img_tensor[2*cw-pad_w:2*cw, 3*cw:,:], 2, [0,1])\n",
    "    # left\n",
    "    canvas[cw+pad_w:2*cw+pad_w, 0:2,:] = img_tensor[cw:2*cw, -2:,:]\n",
    "    # right\n",
    "    canvas[cw+pad_w:2*cw+pad_w, -2:,:] = img_tensor[cw:2*cw, 0:2,:]\n",
    "\n",
    "    # Rotate and copy\n",
    "    canvas[cw:cw+pad_w, :cw+pad_w,:] = torch.rot90(canvas[:cw+pad_w, cw+pad_w:cw+pad_w*2,:], 1, [0,1])\n",
    "    canvas[:cw+pad_w, cw:cw+pad_w,:] = torch.rot90(canvas[cw+pad_w:cw+pad_w*2, :cw+pad_w,:], 3, [0,1])\n",
    "    canvas[2*cw+pad_w:2*cw+pad_w*2, :cw+pad_w,:] = torch.rot90(canvas[2*cw+pad_w:, cw+pad_w:cw+pad_w*2,:], 3, [0,1])\n",
    "    canvas[2*cw+pad_w:, cw:cw+pad_w,:] = torch.rot90(canvas[2*cw:2*cw+pad_w, :cw+pad_w,:], 1, [0,1])\n",
    "    canvas[cw:cw+pad_w, 2*cw+pad_w:3*cw+pad_w*2,:] = torch.rot90(canvas[:cw+pad_w, 2*cw:2*cw+pad_w,:], 3, [0,1])\n",
    "    canvas[:cw+pad_w, 2*cw+pad_w:2*cw+pad_w*2,:] = torch.rot90(canvas[cw+pad_w:cw+pad_w*2, 2*cw+pad_w:3*cw+pad_w*2,:], 1, [0,1])\n",
    "    canvas[2*cw+pad_w:2*cw+pad_w*2, 2*cw+pad_w:3*cw+pad_w,:] = torch.rot90(canvas[2*cw+pad_w:-pad_w, 2*cw:2*cw+pad_w,:], 1, [0,1])\n",
    "    canvas[2*cw+pad_w:, 2*cw+pad_w:2*cw+pad_w*2,:] = torch.rot90(canvas[2*cw:2*cw+pad_w, 2*cw+pad_w:3*cw+pad_w*2,:], 3, [0,1])\n",
    "    \n",
    "    # Flip and copy\n",
    "    #canvas[cw:cw+2, 3*cw+2:,:] = torch.flip(canvas[3:1:-1, 2*cw+1:cw-1:-1,:], [0,1])\n",
    "    #canvas[2*cw+2:2*cw+4, 3*cw+2:,:] = torch.flip(canvas[-3:-5:-1, 2*cw+1:cw-1:-1,:], [0,1])\n",
    "    \n",
    "    # Convert the tensor back to a numpy array\n",
    "    return canvas#.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube_to_equirectangular_torch(img, width, device):\n",
    "    # imgをテンソルに変換\n",
    "    img_tensor = torch.tensor(img, device=device).float()\n",
    "\n",
    "    img_w = width\n",
    "    img_h = width // 2\n",
    "    width = img.shape[1] // 4\n",
    "    print(img_h, img_w, width)\n",
    "\n",
    "    x, y, z = create_3dmap_from_size_torch(img_w, img_h, device)\n",
    "\n",
    "    w = 0.5\n",
    "\n",
    "    # front\n",
    "    xx = w*y / x + w\n",
    "    yy = w*z / x + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (x > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, 0)\n",
    "    tmpy = torch.where(mask, yy*width + width, 0)\n",
    "     \n",
    "    xx = w*y / x + w\n",
    "    yy = -w*z / x + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (x < 0)\n",
    "    tmpx = torch.where(mask, xx*width + width*3, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    xx = -w*x / y + w\n",
    "    yy = w*z / y + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (y > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width*2, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    xx = -w*x / y + w\n",
    "    yy = -w*z / y + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (y < 0)\n",
    "    tmpx = torch.where(mask, xx*width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    xx = -w*y / z + w\n",
    "    yy = -w*x / z + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (z < 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width, tmpy)\n",
    "\n",
    "    xx = w*y / z + w\n",
    "    yy = -w*x / z + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (z > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width*2, tmpy)\n",
    "\n",
    "    cube = padding_cube(img, device).permute(1, 0, 2)\n",
    "    print(cube.shape, type(cube))\n",
    "\n",
    "    # grid_sampleを使うための座標の変換\n",
    "    grid = torch.stack((2*y/img_h - 1, 2*x/img_w - 1), dim=-1)\n",
    "    grid = grid.unsqueeze(0)  \n",
    "\n",
    "    cube_np = cube.cpu().numpy().astype(np.uint8)\n",
    "    ret = cv2.remap(cube_np, tmpx.cpu().numpy().astype(np.float32), tmpy.cpu().numpy().astype(np.float32), interpolation=cv2.INTER_LINEAR)\n",
    "    #print(output.shape, type(output))\n",
    "\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube_to_equirectangular_torch(img, width, device):\n",
    "    # imgをテンソルに変換\n",
    "    img_tensor = torch.tensor(img, device=device).float()\n",
    "\n",
    "    img_w = width\n",
    "    img_h = width // 2\n",
    "    width = img_tensor.shape[1] // 4\n",
    "    print(img_h, img_w, width)\n",
    "\n",
    "    x, y, z = create_3dmap_from_size_torch(img_w, img_h, device)\n",
    "\n",
    "    w = 0.5\n",
    "\n",
    "    # front\n",
    "    xx = w*y / x + w\n",
    "    yy = w*z / x + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (x > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, 0)\n",
    "    tmpy = torch.where(mask, yy*width + width, 0)\n",
    "     \n",
    "    # back\n",
    "    xx = w*y / x + w\n",
    "    yy = -w*z / x + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (x < 0)\n",
    "    tmpx = torch.where(mask, xx*width + width*3, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    #right\n",
    "    xx = -w*x / y + w\n",
    "    yy = w*z / y + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (y > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width*2, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    #left\n",
    "    xx = -w*x / y + w\n",
    "    yy = -w*z / y + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (y < 0)\n",
    "    tmpx = torch.where(mask, xx*width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width, tmpy)\n",
    "     \n",
    "    #up\n",
    "    xx = -w*y / z + w\n",
    "    yy = -w*x / z + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (z < 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width, tmpy)\n",
    "     \n",
    "    #bottom\n",
    "    xx = w*y / z + w\n",
    "    yy = -w*x / z + w    \n",
    "    mask = (xx > 0) & (xx < 1) & (yy > 0) & (yy < 1) & (z > 0)\n",
    "    tmpx = torch.where(mask, xx*width + width, tmpx)\n",
    "    tmpy = torch.where(mask, yy*width + width*2, tmpy)\n",
    "\n",
    "    cube = padding_cube(img, device)\n",
    "    # Offset\n",
    "    tmpx += (2.0 - 0.5)\n",
    "    tmpy += (2.0 - 0.5)\n",
    "    \n",
    "    # Convert back to numpy for remap\n",
    "    cube_np = cube.cpu().numpy()\n",
    "    tmpx_np = tmpx.cpu().numpy().astype(np.float32)\n",
    "    tmpy_np = tmpy.cpu().numpy().astype(np.float32)\n",
    "\n",
    "    ret_img = cv2.remap(cube_np, tmpx_np, tmpy_np, interpolation=cv2.INTER_LINEAR)\n",
    "    ret_img = cv2.rotate(ret_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    ret_img = cv2.flip(ret_img, 0)\n",
    "    \n",
    "    return ret_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 3840, 3)\n",
      "1920 3840 960\n"
     ]
    }
   ],
   "source": [
    "print(cube_img.shape)\n",
    "immm = cube_to_equirectangular_torch(cube_img, 1920*2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"eq2.jpg\", immm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
