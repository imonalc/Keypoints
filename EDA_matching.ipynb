{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imonalc/anaconda3/envs/keypoints/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+'/fivepoint')\n",
    "import build.fivep as f\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from spherical_distortion.functional import create_tangent_images, unresample\n",
    "from spherical_distortion.util import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _spherical_distortion_ext._mesh as _mesh\n",
    "import argparse\n",
    "\n",
    "from random import sample\n",
    "import imageio\n",
    "from scipy.spatial.transform import Rotation as Rot\n",
    "\n",
    "from utils.coord    import coord_3d\n",
    "from utils.ransac   import *\n",
    "from utils.keypoint import *\n",
    "from utils.metrics  import *\n",
    "from utils.camera_recovering import *\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.getcwd()+'/SPHORB-master')\n",
    "\n",
    "import build1.sphorb_cpp as sphorb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(pts1, pts2, desc1, desc2, points):\n",
    "\n",
    "    ind1 = np.argsort(pts1[:,2].numpy(),axis = 0)[::-1]\n",
    "    ind2 = np.argsort(pts2[:,2].numpy(),axis = 0)[::-1]\n",
    "\n",
    "    max1 = np.min([points,ind1.shape[0]])\n",
    "    max2 = np.min([points,ind2.shape[0]])\n",
    "\n",
    "    ind1 = ind1[:max1]\n",
    "    ind2 = ind2[:max2]\n",
    "\n",
    "    pts1 = pts1[ind1.copy(),:]\n",
    "    pts2 = pts2[ind2.copy(),:]\n",
    "\n",
    "    desc1 = desc1[:,ind1.copy()]\n",
    "    desc2 = desc2[:,ind2.copy()]\n",
    "\n",
    "    pts1 = np.concatenate((pts1[:,:2], np.ones((pts1.shape[0],1))), axis = 1 )\n",
    "    pts2 = np.concatenate((pts2[:,:2], np.ones((pts2.shape[0],1))), axis = 1 )\n",
    "\n",
    "    desc1 = np.transpose(desc1,[1,0]).numpy()\n",
    "    desc2 = np.transpose(desc2,[1,0]).numpy()\n",
    "\n",
    "    return pts1, pts2, desc1, desc2\n",
    "\n",
    "\n",
    "def mnn_mather(desc1, desc2, method=\"mean_std\"):\n",
    "    sim = desc1 @ desc2.transpose()\n",
    "    if method == \"mean_std\":\n",
    "        k = 4\n",
    "        threshold = sim.mean() + k * sim.std()\n",
    "    sim_raw = sim.copy()\n",
    "    sim[sim < threshold] = 0\n",
    "    nn12 = np.argmax(sim, axis=1)\n",
    "    nn21 = np.argmax(sim, axis=0)\n",
    "    ids1 = np.arange(0, sim.shape[0])\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = np.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.transpose(), sim_raw\n",
    "\n",
    "\n",
    "def matched_points(pts1, pts2, desc1, desc2, opt, args_opt, match='ratio', use_new_method=0):\n",
    "    if opt[-1] == 'p':\n",
    "        porce = int(opt[:-1])\n",
    "        n_key = int(porce/100 * pts1.shape[0])\n",
    "    else:\n",
    "        n_key = int(opt)\n",
    "\n",
    "    s_pts1  = pts1.copy()[:n_key,:]\n",
    "    s_pts2  = pts2.copy()[:n_key,:]\n",
    "    s_desc1 = desc1.copy().astype('float32')[:n_key,:]\n",
    "    s_desc2 = desc2.copy().astype('float32')[:n_key,:]\n",
    "\n",
    "    if 'orb' in args_opt:\n",
    "        s_desc1 = s_desc1.astype(np.uint8)\n",
    "        s_desc2 = s_desc2.astype(np.uint8)\n",
    "        hamming_distances = np.array([[cv2.norm(d1, d2, cv2.NORM_HAMMING) for d2 in s_desc2] for d1 in s_desc1])\n",
    "        sim = -hamming_distances\n",
    "        nn12 = np.argmin(hamming_distances, axis=1)\n",
    "        nn21 = np.argmin(hamming_distances, axis=0)\n",
    "        ids1 = np.arange(len(s_desc1))\n",
    "        mask = (ids1 == nn21[nn12])\n",
    "        matches = [cv2.DMatch(i, j, 0) for i, j in zip(ids1[mask], nn12[mask])]\n",
    "    else:\n",
    "        matches_idx, sim = mnn_mather(s_desc1, s_desc2)\n",
    "        matches = [cv2.DMatch(i, j, 0) for i, j in matches_idx]\n",
    "\n",
    "    M = np.zeros((2,len(matches)))\n",
    "    for ind, match in zip(np.arange(len(matches)),matches):\n",
    "        M[0,ind] = match.queryIdx\n",
    "        M[1,ind] = match.trainIdx\n",
    "\n",
    "\n",
    "    return s_pts1, s_pts2, s_pts1[M[0,:].astype(int),:3], s_pts2[M[1,:].astype(int),:3], sim\n",
    "\n",
    "\n",
    "def get_error(x1, x2, Rx, Tx):\n",
    "\n",
    "    S = computeEssentialMatrixByRANSAC(x1, x2)\n",
    "    I = S[1]\n",
    "    I = I.astype(np.int64)\n",
    "\n",
    "    x1 = x1[I,:]\n",
    "    x2 = x2[I,:]\n",
    "\n",
    "    F = calc_ematrix(x1,x2)\n",
    "\n",
    "\n",
    "    R1,R2,T1,T2 = decomposeE(F)\n",
    "\n",
    "    R,T = choose_rt(R1,R2,T1,T2,x1,x2)\n",
    "\n",
    "    R_error = r_error(Rx,R)\n",
    "    T_error = t_error(Tx,T)\n",
    "\n",
    "    return R_error, T_error\n",
    "\n",
    "\n",
    "def get_descriptor(descriptor):\n",
    "    if descriptor == 'sphorb':\n",
    "        return 'sphorb', 'erp', 640, 0\n",
    "    elif descriptor == 'sift':\n",
    "        return 'sift', 'erp', 512, 0\n",
    "    elif descriptor == 'tsift':\n",
    "        return 'sift', 'tangent', 512, 0\n",
    "    elif descriptor == 'orb':\n",
    "        return 'orb', 'erp', 512, 0\n",
    "    elif descriptor == 'torb':\n",
    "        return 'orb', 'tangent', 512, 0\n",
    "    elif descriptor == 'spoint':\n",
    "        return 'superpoint', 'erp', 512, 0\n",
    "    elif descriptor == 'tspoint':\n",
    "        return 'superpoint', 'tangent', 512, 0\n",
    "    elif descriptor == 'alike':\n",
    "        return 'alike', 'erp', 512, 0\n",
    "    elif descriptor == 'talike':\n",
    "        return 'alike', 'tangent', 512, 0\n",
    "    elif descriptor == 'Proposed':\n",
    "        return 'superpoint', 'tangent', 512, 1\n",
    "    elif descriptor == 'Ltspoint':\n",
    "        return 'superpoint', 'tangent', 512, 2\n",
    "    elif descriptor == 'Ftspoint':\n",
    "        return 'superpoint', 'tangent', 512, 3\n",
    "\n",
    "\n",
    "def get_error(x1, x2, Rx, Tx):\n",
    "\n",
    "    S = computeEssentialMatrixByRANSAC(x1, x2)\n",
    "    I = S[1]\n",
    "    I = I.astype(np.int64)\n",
    "\n",
    "    x1 = x1[I,:]\n",
    "    x2 = x2[I,:]\n",
    "\n",
    "    F = calc_ematrix(x1,x2)\n",
    "\n",
    "\n",
    "    R1,R2,T1,T2 = decomposeE(F)\n",
    "\n",
    "    R,T = choose_rt(R1,R2,T1,T2,x1,x2)\n",
    "\n",
    "    R_error = r_error(Rx,R)\n",
    "    T_error = t_error(Tx,T)\n",
    "\n",
    "    return R_error, T_error\n",
    "\n",
    "\n",
    "def AUC(ROT, TRA, MET, L):\n",
    "\n",
    "    RAUC  = np.zeros(len(L))\n",
    "    TAUC  = np.zeros(len(L))\n",
    "\n",
    "    for index, t in enumerate(L):\n",
    "        ids = np.where(ROT<np.radians(t))[0]\n",
    "        RAUC[index] = len(ids)/len(ROT)\n",
    "\n",
    "    for index, t in enumerate(L):\n",
    "        ids = np.where(TRA<np.radians(t))[0]\n",
    "        TAUC[index] = len(ids)/len(TRA)\n",
    "\n",
    "    return RAUC, TAUC, np.array(MET)\n",
    "\n",
    "\n",
    "def get_data(DATAS):\n",
    "    if len(DATAS) == 1:\n",
    "        data = DATAS[0]\n",
    "    elif set(['Urban1','Urban2','Urban3','Urban4']) == set(DATAS):\n",
    "        data = 'Outdoor'\n",
    "    elif set(['Realistic','Interior1','Interior2','Room','Classroom']) == set(DATAS):\n",
    "        data = 'Indoor'\n",
    "    elif set(['Urban1_R','Urban2_R','Urban3_R','Urban4_R','Realistic_R','Interior1_R','Interior2_R','Room_R','Classroom_R']) == set(DATAS):\n",
    "        data = 'OnlyRot'\n",
    "    elif set(['Urban1_T','Urban2_T','Urban3_T','Urban4_T','Realistic_T','Interior1_T','Interior2_T','Room_T','Classroom_T']) == set(DATAS):\n",
    "        data = 'OnlyTra'\n",
    "    else:\n",
    "        data = ''\n",
    "        for DA in DATAS:\n",
    "            data+=DA\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_kd(array):\n",
    "\n",
    "    array = np.array(array)\n",
    "    delimiter = int(array[-1])\n",
    "    A = array[:-1]\n",
    "    K = A[:delimiter].reshape(-1,3)\n",
    "    D = A[delimiter:].reshape(-1,32)\n",
    "    return K,D\n",
    "\n",
    "\n",
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis=1, keepdims=True)\n",
    "    normalized_features = features / norms\n",
    "\n",
    "    threshold = 0.2\n",
    "    normalized_features = np.minimum(normalized_features, threshold)\n",
    "\n",
    "    norms = np.linalg.norm(normalized_features, axis=1, keepdims=True)\n",
    "    normalized_features /= norms\n",
    "\n",
    "    return normalized_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = 500\n",
    "match = \"ratio\"\n",
    "solver = \"None\"\n",
    "inliers = \"5PA\"\n",
    "descriptor = \"tsift\"\n",
    "path = \"./data/Farm_pair\"  #\"./data/data_100/Room/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(points = 500,\n",
    "match = \"ratio\",\n",
    "descriptor = \"tsift\",\n",
    "path = \"./data/Farm_pair\",):\n",
    "    t0 = time.time()\n",
    "    descriptor = descriptor\n",
    "\n",
    "    opt, mode, sphered, use_our_method = get_descriptor(descriptor)\n",
    "    base_order = 0  # Base sphere resolution\n",
    "    sample_order = 8  # Determines sample resolution (10 = 2048 x 4096)\n",
    "    scale_factor = 1.0  # How much to scale input equirectangular image by\n",
    "    save_ply = False  # Whether to save the PLY visualizations too\n",
    "    dim = np.array([2*sphered, sphered])\n",
    "\n",
    "    path_o = path + '/O.png'\n",
    "    path_r = path + '/R.png'\n",
    "    img_o = load_torch_img(path_o)[:3, ...].float()\n",
    "    img_o = F.interpolate(img_o.unsqueeze(0), scale_factor=scale_factor, mode='bilinear', align_corners=False, recompute_scale_factor=True).squeeze(0)\n",
    "    img_r = load_torch_img(path_r)[:3, ...].float()\n",
    "    img_r = F.interpolate(img_r.unsqueeze(0), scale_factor=scale_factor, mode='bilinear', align_corners=False, recompute_scale_factor=True).squeeze(0)\n",
    "    img_o = torch2numpy(img_o.byte())\n",
    "    img_r = torch2numpy(img_r.byte())\n",
    "    img_o = cv2.cvtColor(img_o, cv2.COLOR_BGR2RGB)\n",
    "    img_r = cv2.cvtColor(img_r, cv2.COLOR_BGR2RGB)\n",
    "    height_threshold = 0.7 * img_o.shape[0]\n",
    "\n",
    "\n",
    "    print(path_o)\n",
    "    t1 = time.time()\n",
    "    print(\"image:\", t1-t0)\n",
    "    if opt != 'sphorb':\n",
    "        corners = tangent_image_corners(base_order, sample_order)\n",
    "        pts1, desc1 = process_image_to_keypoints(path_o, corners, scale_factor, base_order, sample_order, opt, mode)\n",
    "        print(descriptor, len(pts1))\n",
    "        pts2, desc2 = process_image_to_keypoints(path_r, corners, scale_factor, base_order, sample_order, opt, mode)\n",
    "        pts1[pts1[:,0] > img_o.shape[1], 0] -= img_o.shape[1]\n",
    "        pts2[pts2[:,0] > img_o.shape[1], 0] -= img_o.shape[1]\n",
    "    else:      \n",
    "        os.chdir('SPHORB-master/')\n",
    "        pts1, desc1 = get_kd(sphorb.sphorb(path_o, points))\n",
    "        pts2, desc2 = get_kd(sphorb.sphorb(path_r, points))\n",
    "        os.chdir('../')\n",
    "    if opt == \"sift\":\n",
    "        desc1 = normalize_features(desc1)\n",
    "        desc2 = normalize_features(desc2)\n",
    "\n",
    "    #print(desc1.shape, desc1)\n",
    "    pts1, pts2, desc1, desc2 = sort_key(pts1, pts2, desc1, desc2, points)\n",
    "    t2 = time.time()\n",
    "    print(\"detection:\", t2-t1)\n",
    "    if len(pts1.shape) == 1:\n",
    "        pts1 = pts1.reshape(1,-1)\n",
    "\n",
    "    print(desc1.shape)\n",
    "    s_pts1, s_pts2, x1, x2, sim = matched_points(pts1, pts2, desc1, desc2, \"100p\", opt, match, use_new_method=use_our_method)\n",
    "    print()\n",
    "    #print(x1[:5])\n",
    "    #print(desc1[:5],)\n",
    "    sim = -sim\n",
    "    sim = (sim - np.min(sim)) / (np.max(sim) - np.min(sim))\n",
    "    #print(sim[:5])\n",
    "    return sim, x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Farm_pair/O.png\n",
      "image: 0.30002284049987793\n",
      "Proposed 606\n",
      "detection: 1.2272167205810547\n",
      "(500, 256)\n",
      "\n",
      "[[0.7387523  0.57731444 0.75546753 ... 0.7078584  0.6948713  0.81339633]\n",
      " [0.74364936 0.688245   0.75579    ... 0.70178986 0.7390656  0.7181975 ]\n",
      " [0.32185107 0.71577114 0.73720515 ... 0.7277505  0.7387182  0.691754  ]\n",
      " [0.3534079  0.75297564 0.7653046  ... 0.7411455  0.6986666  0.6885239 ]\n",
      " [0.55149937 0.7949119  0.75320345 ... 0.7720933  0.83194184 0.7562096 ]]\n",
      "./data/Farm_pair/O.png\n",
      "image: 0.320812463760376\n",
      "spoint 21781\n",
      "detection: 1.4440572261810303\n",
      "(500, 256)\n",
      "\n",
      "[[0.6358735  0.6052344  0.6737824  ... 0.66104    0.67065793 0.68292046]\n",
      " [0.6872951  0.64161325 0.70150363 ... 0.34419656 0.6179201  0.68636084]\n",
      " [0.446369   0.6168526  0.5468437  ... 0.788171   0.7226232  0.8085861 ]\n",
      " [0.794013   0.77078307 0.54308    ... 0.81109136 0.6840271  0.6667871 ]\n",
      " [0.43693468 0.7499981  0.543808   ... 0.7931081  0.6592515  0.70623964]]\n"
     ]
    }
   ],
   "source": [
    "sim_p, x1_p, x2_p = test(descriptor=\"Proposed\")\n",
    "sim_sp, x1_sp, x2_sp = test(descriptor=\"spoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list = [sim_sp, sim_p]\n",
    "nm_list = [\"SPoint\", \"Tspoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dict = {\n",
    "    \"spoint\": (sim_sp, x1_sp, x2_sp),\n",
    "    \"tspoint\":( sim_p, x1_p, x2_p),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"sim_matching.pickle\", mode='wb') as f:\n",
    "    pickle.dump(sim_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8222279936075211\n"
     ]
    }
   ],
   "source": [
    "threshold = np.percentile(sim_p, 95)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_idx_list = []\n",
    "simsp_idx_list = []\n",
    "for idx_x1 in range(500):\n",
    "    for idx_x2 in range(500):\n",
    "        simp_idx_list.append([sim_p[idx_x1][idx_x2], idx_x1, idx_x2])\n",
    "        simsp_idx_list.append([sim_sp[idx_x1][idx_x2], idx_x1, idx_x2])\n",
    "\n",
    "\n",
    "simp_idx_list.sort(reverse=True) \n",
    "simsp_idx_list.sort(reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "simp_idx_x1_list = []\n",
    "simp_idx_x2_list = []\n",
    "simsp_idx_x2_list = []\n",
    "simsp_idx_x1_list = []\n",
    "\n",
    "simp_idx_list_unique = []\n",
    "for idx in range(len(simp_idx_list)):\n",
    "    sim, idx_x1, idx_x2 = simp_idx_list[idx]\n",
    "    flag = False\n",
    "    if idx_x1 in simp_idx_x1_list: flag = True\n",
    "    if idx_x2 in simp_idx_x2_list: flag = True\n",
    "    simp_idx_x1_list.append(idx_x1)\n",
    "    simp_idx_x2_list.append(idx_x2)\n",
    "    if flag: continue\n",
    "    simp_idx_list_unique.append(sim)\n",
    "\n",
    "print(len(simp_idx_list_unique))\n",
    "\n",
    "simsp_idx_list_unique = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.97981495,\n",
       " 0.97968006,\n",
       " 0.97908735,\n",
       " 0.9772731,\n",
       " 0.97233063,\n",
       " 0.9707402,\n",
       " 0.96797967,\n",
       " 0.9676867,\n",
       " 0.9657811,\n",
       " 0.96300775,\n",
       " 0.96127665,\n",
       " 0.9588784,\n",
       " 0.9560634,\n",
       " 0.9550731,\n",
       " 0.953602,\n",
       " 0.95334524,\n",
       " 0.9523523,\n",
       " 0.95204896,\n",
       " 0.95025635,\n",
       " 0.94958466,\n",
       " 0.94876516,\n",
       " 0.94719046,\n",
       " 0.9465559,\n",
       " 0.94649017,\n",
       " 0.9438842,\n",
       " 0.9426292,\n",
       " 0.94251347,\n",
       " 0.9416456,\n",
       " 0.94115883,\n",
       " 0.9410301,\n",
       " 0.94048613,\n",
       " 0.94012636,\n",
       " 0.9389956,\n",
       " 0.93896884,\n",
       " 0.9389643,\n",
       " 0.9387997,\n",
       " 0.9377583,\n",
       " 0.9377183,\n",
       " 0.9372677,\n",
       " 0.9371908,\n",
       " 0.9360279,\n",
       " 0.9359062,\n",
       " 0.93582666,\n",
       " 0.93522376,\n",
       " 0.93496346,\n",
       " 0.9339908,\n",
       " 0.93377215,\n",
       " 0.93345255,\n",
       " 0.9328581,\n",
       " 0.9321327,\n",
       " 0.932047,\n",
       " 0.9315888,\n",
       " 0.9304759,\n",
       " 0.9293803,\n",
       " 0.9292498,\n",
       " 0.9291499,\n",
       " 0.92849505,\n",
       " 0.927503,\n",
       " 0.9273187,\n",
       " 0.92712766,\n",
       " 0.9268669,\n",
       " 0.9266633,\n",
       " 0.92542404,\n",
       " 0.9251957,\n",
       " 0.92477816,\n",
       " 0.9237096,\n",
       " 0.92365277,\n",
       " 0.92292607,\n",
       " 0.922713,\n",
       " 0.9222999,\n",
       " 0.9213546,\n",
       " 0.92119235,\n",
       " 0.92059153,\n",
       " 0.92056876,\n",
       " 0.9204355,\n",
       " 0.9190096,\n",
       " 0.9188801,\n",
       " 0.91813797,\n",
       " 0.9180027,\n",
       " 0.91732913,\n",
       " 0.9171616,\n",
       " 0.91712743,\n",
       " 0.91683894,\n",
       " 0.91673577,\n",
       " 0.9166954,\n",
       " 0.9163117,\n",
       " 0.91621417,\n",
       " 0.91549456,\n",
       " 0.91498345,\n",
       " 0.91489035,\n",
       " 0.914607,\n",
       " 0.914154,\n",
       " 0.9138445,\n",
       " 0.9126396,\n",
       " 0.9124701,\n",
       " 0.91193366,\n",
       " 0.9104754,\n",
       " 0.9104047,\n",
       " 0.9101786,\n",
       " 0.909686,\n",
       " 0.9095191,\n",
       " 0.90924317,\n",
       " 0.9091154,\n",
       " 0.90754145,\n",
       " 0.90738106,\n",
       " 0.90734524,\n",
       " 0.9071447,\n",
       " 0.90654325,\n",
       " 0.9062423,\n",
       " 0.9060185,\n",
       " 0.9053899,\n",
       " 0.9048561,\n",
       " 0.90427816,\n",
       " 0.903019,\n",
       " 0.9006847,\n",
       " 0.9005275,\n",
       " 0.89986485,\n",
       " 0.8996928,\n",
       " 0.89902294,\n",
       " 0.8985532,\n",
       " 0.8978028,\n",
       " 0.8962104,\n",
       " 0.8951119,\n",
       " 0.89473426,\n",
       " 0.8939437,\n",
       " 0.892925,\n",
       " 0.89081216,\n",
       " 0.8903584,\n",
       " 0.8884582,\n",
       " 0.88842404,\n",
       " 0.8883008,\n",
       " 0.8869809,\n",
       " 0.88652056,\n",
       " 0.88624835,\n",
       " 0.88609314,\n",
       " 0.8843293,\n",
       " 0.8837929,\n",
       " 0.88288397,\n",
       " 0.8812487,\n",
       " 0.87152886,\n",
       " 0.86943567,\n",
       " 0.8667992]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_idx_list_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simp_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
