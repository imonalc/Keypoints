{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "device = 'cuda:0'\n",
    "\n",
    "# 関数定義\n",
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"ij\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 1024, 512\n",
    "coords = equirectangular_to_spherical_coords(img_width, img_height, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# テスト関数\n",
    "def test_equirectangular_to_spherical_coords():\n",
    "    # 画像の幅と高さ\n",
    "    img_width, img_height = 360, 180\n",
    "    \n",
    "    # デバイス設定\n",
    "    device = 'cpu'\n",
    "    \n",
    "    # 関数から座標を取得\n",
    "    coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    \n",
    "    # 仰角θのテスト\n",
    "    assert torch.allclose(coords[:, :, 0].min(), torch.tensor(0.0, device=device)), \"Minimum theta should be 0\"\n",
    "    assert torch.allclose(coords[:, :, 0].max(), torch.tensor(np.pi, device=device)), \"Maximum theta should be pi\"\n",
    "    \n",
    "    # 方位角φのテスト\n",
    "    assert torch.allclose(coords[:, :, 1].min(), torch.tensor(0.0, device=device)), \"Minimum phi should be 0\"\n",
    "    assert torch.allclose(coords[:, :, 1].max(), torch.tensor(2 * np.pi, device=device)), \"Maximum phi should be 2*pi\"\n",
    "    \n",
    "    # すべてのテストが成功した場合のメッセージ\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# テスト関数を呼び出し\n",
    "test_equirectangular_to_spherical_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_spherical_coords(spherical_coords):\n",
    "    # θ (theta) と φ (phi) を抽出する\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    # φの値に基づいてθを調整する\n",
    "    theta_adjusted = torch.where((phi < torch.pi), theta + torch.pi / 4, theta + torch.pi / 4)\n",
    "\n",
    "    # θがπを超える場合の調整\n",
    "    theta_adjusted = torch.where(theta_adjusted < torch.pi, theta_adjusted, 2 * torch.pi - theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted < torch.pi, phi, 2 * torch.pi - phi)\n",
    "\n",
    "    # θが0未満の場合の調整\n",
    "    theta_adjusted = torch.where(theta_adjusted >= 0, theta_adjusted, -theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted >= 0, phi_adjusted, 2 * torch.pi - phi_adjusted)\n",
    "\n",
    "    # 更新された値で新しい座標配列を構築\n",
    "    new_coords = torch.stack([theta_adjusted, phi_adjusted, torch.ones_like(theta_adjusted)], dim=-1)\n",
    "    \n",
    "    return new_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coords = adjust_spherical_coords(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.8540e-01, 0.0000e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 0.0000e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 0.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 0.0000e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 0.0000e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.1419e-03, 1.0000e+00],\n",
      "         [7.9155e-01, 6.1419e-03, 1.0000e+00],\n",
      "         [7.9769e-01, 6.1419e-03, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.1419e-03, 1.0000e+00],\n",
      "         [2.3623e+00, 6.1419e-03, 1.0000e+00],\n",
      "         [2.3562e+00, 6.1419e-03, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 1.2284e-02, 1.0000e+00],\n",
      "         [7.9155e-01, 1.2284e-02, 1.0000e+00],\n",
      "         [7.9769e-01, 1.2284e-02, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 1.2284e-02, 1.0000e+00],\n",
      "         [2.3623e+00, 1.2284e-02, 1.0000e+00],\n",
      "         [2.3562e+00, 1.2284e-02, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.8540e-01, 6.2709e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2709e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2709e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2709e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2709e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2709e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.2770e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2770e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2770e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2770e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2770e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2770e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.2832e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2832e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2832e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2832e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2832e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2832e+00, 1.0000e+00]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(new_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_to_equirectangular_coords(spherical_coords, img_width, img_height):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    # 画像の高さと幅に基づいてピクセル座標を計算\n",
    "    x = (phi / (2 * torch.pi)) * img_width  # 0 <= φ < 2π の範囲で img_width にマッピング\n",
    "    y = (theta / torch.pi) * img_height     # 0 <= θ < π の範囲で img_height にマッピング\n",
    "\n",
    "    # 座標が整数値である必要があるため、最も近い整数に丸める\n",
    "    x = torch.round(x).long() % img_width   # img_width を超えないようにする\n",
    "    y = torch.round(y).long() % img_height  # img_height を超えないようにする\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3dmap_from_size_torch(img_w, img_h, device):\n",
    "    h = torch.linspace(-np.pi/2, np.pi/2, img_h, device=device)\n",
    "    w = torch.linspace(-np.pi, np.pi, img_w, device=device)\n",
    "    \n",
    "    h += (np.pi/2) / img_h\n",
    "    w += np.pi / img_w\n",
    "    \n",
    "    theta, phi = torch.meshgrid(w, h, indexing=\"ij\")\n",
    "    \n",
    "    x = torch.cos(phi) * torch.cos(theta)\n",
    "    y = torch.cos(phi) * torch.sin(theta)\n",
    "    z = torch.sin(phi)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"xy\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)\n",
    "\n",
    "def adjust_spherical_coords(spherical_coords):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    theta_adjusted = torch.where((phi < torch.pi), theta + torch.pi / 4, theta - torch.pi / 4)\n",
    "    phi_adjusted = torch.where(theta_adjusted < torch.pi, phi, 2 * torch.pi - phi)\n",
    "    theta_adjusted = torch.where(theta_adjusted < torch.pi, theta_adjusted, 2 * torch.pi - theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted >= 0, phi_adjusted, 2 * torch.pi - phi_adjusted)\n",
    "    theta_adjusted = torch.where(theta_adjusted >= 0, theta_adjusted, -theta_adjusted)\n",
    "    return torch.stack([theta_adjusted, phi_adjusted, torch.ones_like(theta_adjusted)], dim=-1)\n",
    "\n",
    "\n",
    "def spherical_to_equirectangular_coords(spherical_coords, img_width, img_height):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "    x = (phi / (2 * torch.pi)) * img_width\n",
    "    y = (theta / torch.pi) * img_height\n",
    "    x = torch.round(x).long() % img_width\n",
    "    y = torch.round(y).long() % img_height\n",
    "    return x, y\n",
    "\n",
    "def transform_equirectangular_image(img):\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    adjusted_coords = adjust_spherical_coords(spherical_coords)\n",
    "    x, y = spherical_to_equirectangular_coords(adjusted_coords, img_width, img_height)\n",
    "    #x, y = spherical_to_equirectangular_coords(spherical_coords, img_width, img_height)\n",
    "\n",
    "    # 新しい画像を作成\n",
    "    transformed_img = torch.zeros_like(img)\n",
    "    for i in range(img_height):\n",
    "        for j in range(img_width):\n",
    "            y_idx = min(max(y[i, j], 0), img_height - 1)\n",
    "            x_idx = min(max(x[i, j], 0), img_width - 1)\n",
    "            transformed_img[y_idx, x_idx] = img[i, j]\n",
    "    return transformed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "#cv2.imshow(\"Frame\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "img = torch.from_numpy(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = transform_equirectangular_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img2.is_cuda:\n",
    "    img2 = img2.cpu()\n",
    "\n",
    "# Tensor を NumPy 配列に変換\n",
    "img_numpy = img2.numpy()\n",
    "\n",
    "# データ型が float の場合、0-255 に正規化して uint8 に変換\n",
    "if img_numpy.dtype == np.float32 or img_numpy.dtype == np.float64:\n",
    "    img_numpy = (img_numpy * 255).astype(np.uint8)\n",
    "\n",
    "# チャネルの順序が (C, H, W) の場合、(H, W, C) に変更し、BGR に変換\n",
    "if img_numpy.shape[0] == 3:\n",
    "    img_numpy = img_numpy.transpose(1, 2, 0)  # C, H, W -> H, W, C\n",
    "    img_numpy = cv2.cvtColor(img_numpy, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"Frame\", img_numpy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "img_height, img_width = img.shape[:2]\n",
    "spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "adjusted_coords = adjust_spherical_coords(spherical_coords)\n",
    "x, y = spherical_to_equirectangular_coords(adjusted_coords, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"./data/example/room1/R.png\")\n",
    "img2 = cv2.resize(img , (1024, 512))\n",
    "cv2.imwrite(\"./data/example/room3/R.png\" , img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 画像の読み込み\n",
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "img = cv2.imread(\"./data/example/room3/O.png\")\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "w_half = int(w / 2)\n",
    "h_half = int(h / 2)\n",
    "\n",
    "# メッシュグリッドの生成\n",
    "phi, theta = np.meshgrid(np.linspace(-np.pi, np.pi, w_half*2),\n",
    "                         np.linspace(-np.pi/2, np.pi/2, h_half*2))\n",
    "\n",
    "\n",
    "# 球面座標\n",
    "x = np.cos(theta) * np.cos(phi)\n",
    "y = np.cos(theta) * np.sin(phi)\n",
    "z = np.sin(theta)\n",
    "\n",
    "# z軸周りにπ/2ラジアン回転\n",
    "rot = np.pi / 2\n",
    "xx = x * np.cos(rot) + z * np.sin(rot)\n",
    "yy = y\n",
    "zz = -x * np.sin(rot) + z * np.cos(rot)\n",
    "\n",
    "# 逆球面座標変換\n",
    "theta = np.arcsin(zz)\n",
    "phi = np.arctan2(yy, xx)\n",
    "\n",
    "# 画像座標へのマッピング\n",
    "Y = 2*theta / np.pi * h_half + h_half\n",
    "X = phi / np.pi * w_half + w_half\n",
    "\n",
    "# 画像のリマッピングと保存\n",
    "out = cv2.remap(img, X.astype(np.float32), Y.astype(np.float32), cv2.INTER_LINEAR, borderMode=cv2.BORDER_WRAP)\n",
    "cv2.imwrite(\"dst.png\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"xy\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)\n",
    "\n",
    "def is_in_middle_latitude(img_width, img_height, x, y, device='cpu'):\n",
    "    # 全天球画像の座標から球面座標を取得\n",
    "    spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    \n",
    "    # x, y 座標でのシータの値を取得\n",
    "    theta_at_xy = spherical_coords[y, x, 0]\n",
    "    \n",
    "    # θがπ/4から3π/4の間にあるかチェック\n",
    "    return np.pi/4 <= theta_at_xy < 3*np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "a = is_in_middle_latitude(1024, 512, 0, 0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
