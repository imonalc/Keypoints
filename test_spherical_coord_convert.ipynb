{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imonalc/anaconda3/envs/keypoints/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "device = 'cuda:0'\n",
    "\n",
    "# 関数定義\n",
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"ij\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 1024, 512\n",
    "coords = equirectangular_to_spherical_coords(img_width, img_height, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# テスト関数\n",
    "def test_equirectangular_to_spherical_coords():\n",
    "    # 画像の幅と高さ\n",
    "    img_width, img_height = 360, 180\n",
    "    \n",
    "    # デバイス設定\n",
    "    device = 'cpu'\n",
    "    \n",
    "    # 関数から座標を取得\n",
    "    coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    \n",
    "    # 仰角θのテスト\n",
    "    assert torch.allclose(coords[:, :, 0].min(), torch.tensor(0.0, device=device)), \"Minimum theta should be 0\"\n",
    "    assert torch.allclose(coords[:, :, 0].max(), torch.tensor(np.pi, device=device)), \"Maximum theta should be pi\"\n",
    "    \n",
    "    # 方位角φのテスト\n",
    "    assert torch.allclose(coords[:, :, 1].min(), torch.tensor(0.0, device=device)), \"Minimum phi should be 0\"\n",
    "    assert torch.allclose(coords[:, :, 1].max(), torch.tensor(2 * np.pi, device=device)), \"Maximum phi should be 2*pi\"\n",
    "    \n",
    "    # すべてのテストが成功した場合のメッセージ\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# テスト関数を呼び出し\n",
    "test_equirectangular_to_spherical_coords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_spherical_coords(spherical_coords):\n",
    "    # θ (theta) と φ (phi) を抽出する\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    # φの値に基づいてθを調整する\n",
    "    theta_adjusted = torch.where((phi < torch.pi), theta + torch.pi / 4, theta + torch.pi / 4)\n",
    "\n",
    "    # θがπを超える場合の調整\n",
    "    theta_adjusted = torch.where(theta_adjusted < torch.pi, theta_adjusted, 2 * torch.pi - theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted < torch.pi, phi, 2 * torch.pi - phi)\n",
    "\n",
    "    # θが0未満の場合の調整\n",
    "    theta_adjusted = torch.where(theta_adjusted >= 0, theta_adjusted, -theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted >= 0, phi_adjusted, 2 * torch.pi - phi_adjusted)\n",
    "\n",
    "    # 更新された値で新しい座標配列を構築\n",
    "    new_coords = torch.stack([theta_adjusted, phi_adjusted, torch.ones_like(theta_adjusted)], dim=-1)\n",
    "    \n",
    "    return new_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coords = adjust_spherical_coords(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7.8540e-01, 0.0000e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 0.0000e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 0.0000e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 0.0000e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 0.0000e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 0.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.1419e-03, 1.0000e+00],\n",
      "         [7.9155e-01, 6.1419e-03, 1.0000e+00],\n",
      "         [7.9769e-01, 6.1419e-03, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.1419e-03, 1.0000e+00],\n",
      "         [2.3623e+00, 6.1419e-03, 1.0000e+00],\n",
      "         [2.3562e+00, 6.1419e-03, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 1.2284e-02, 1.0000e+00],\n",
      "         [7.9155e-01, 1.2284e-02, 1.0000e+00],\n",
      "         [7.9769e-01, 1.2284e-02, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 1.2284e-02, 1.0000e+00],\n",
      "         [2.3623e+00, 1.2284e-02, 1.0000e+00],\n",
      "         [2.3562e+00, 1.2284e-02, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[7.8540e-01, 6.2709e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2709e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2709e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2709e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2709e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2709e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.2770e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2770e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2770e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2770e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2770e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2770e+00, 1.0000e+00]],\n",
      "\n",
      "        [[7.8540e-01, 6.2832e+00, 1.0000e+00],\n",
      "         [7.9155e-01, 6.2832e+00, 1.0000e+00],\n",
      "         [7.9769e-01, 6.2832e+00, 1.0000e+00],\n",
      "         ...,\n",
      "         [2.3685e+00, 6.2832e+00, 1.0000e+00],\n",
      "         [2.3623e+00, 6.2832e+00, 1.0000e+00],\n",
      "         [2.3562e+00, 6.2832e+00, 1.0000e+00]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(new_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_to_equirectangular_coords(spherical_coords, img_width, img_height):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    # 画像の高さと幅に基づいてピクセル座標を計算\n",
    "    x = (phi / (2 * torch.pi)) * img_width  # 0 <= φ < 2π の範囲で img_width にマッピング\n",
    "    y = (theta / torch.pi) * img_height     # 0 <= θ < π の範囲で img_height にマッピング\n",
    "\n",
    "    # 座標が整数値である必要があるため、最も近い整数に丸める\n",
    "    x = torch.round(x).long() % img_width   # img_width を超えないようにする\n",
    "    y = torch.round(y).long() % img_height  # img_height を超えないようにする\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3dmap_from_size_torch(img_w, img_h, device):\n",
    "    h = torch.linspace(-np.pi/2, np.pi/2, img_h, device=device)\n",
    "    w = torch.linspace(-np.pi, np.pi, img_w, device=device)\n",
    "    \n",
    "    h += (np.pi/2) / img_h\n",
    "    w += np.pi / img_w\n",
    "    \n",
    "    theta, phi = torch.meshgrid(w, h, indexing=\"ij\")\n",
    "    \n",
    "    x = torch.cos(phi) * torch.cos(theta)\n",
    "    y = torch.cos(phi) * torch.sin(theta)\n",
    "    z = torch.sin(phi)\n",
    "    \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"xy\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)\n",
    "\n",
    "def adjust_spherical_coords(spherical_coords):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "\n",
    "    theta_adjusted = torch.where((phi < torch.pi), theta + torch.pi / 4, theta - torch.pi / 4)\n",
    "    phi_adjusted = torch.where(theta_adjusted < torch.pi, phi, 2 * torch.pi - phi)\n",
    "    theta_adjusted = torch.where(theta_adjusted < torch.pi, theta_adjusted, 2 * torch.pi - theta_adjusted)\n",
    "    phi_adjusted = torch.where(theta_adjusted >= 0, phi_adjusted, 2 * torch.pi - phi_adjusted)\n",
    "    theta_adjusted = torch.where(theta_adjusted >= 0, theta_adjusted, -theta_adjusted)\n",
    "    return torch.stack([theta_adjusted, phi_adjusted, torch.ones_like(theta_adjusted)], dim=-1)\n",
    "\n",
    "\n",
    "def spherical_to_equirectangular_coords(spherical_coords, img_width, img_height):\n",
    "    theta, phi, _ = spherical_coords[..., 0], spherical_coords[..., 1], spherical_coords[..., 2]\n",
    "    x = (phi / (2 * torch.pi)) * img_width\n",
    "    y = (theta / torch.pi) * img_height\n",
    "    x = torch.round(x).long() % img_width\n",
    "    y = torch.round(y).long() % img_height\n",
    "    return x, y\n",
    "\n",
    "def transform_equirectangular_image(img):\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    adjusted_coords = adjust_spherical_coords(spherical_coords)\n",
    "    x, y = spherical_to_equirectangular_coords(adjusted_coords, img_width, img_height)\n",
    "    #x, y = spherical_to_equirectangular_coords(spherical_coords, img_width, img_height)\n",
    "\n",
    "    # 新しい画像を作成\n",
    "    transformed_img = torch.zeros_like(img)\n",
    "    for i in range(img_height):\n",
    "        for j in range(img_width):\n",
    "            y_idx = min(max(y[i, j], 0), img_height - 1)\n",
    "            x_idx = min(max(x[i, j], 0), img_width - 1)\n",
    "            transformed_img[y_idx, x_idx] = img[i, j]\n",
    "    return transformed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "#cv2.imshow(\"Frame\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "img = torch.from_numpy(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img2 = transform_equirectangular_image(img)\n",
    "img2 = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if img2.is_cuda:\n",
    "    img2 = img2.cpu()\n",
    "\n",
    "# Tensor を NumPy 配列に変換\n",
    "img_numpy = img2.numpy()\n",
    "\n",
    "# データ型が float の場合、0-255 に正規化して uint8 に変換\n",
    "if img_numpy.dtype == np.float32 or img_numpy.dtype == np.float64:\n",
    "    img_numpy = (img_numpy * 255).astype(np.uint8)\n",
    "\n",
    "# チャネルの順序が (C, H, W) の場合、(H, W, C) に変更し、BGR に変換\n",
    "if img_numpy.shape[0] == 3:\n",
    "    img_numpy = img_numpy.transpose(1, 2, 0)  # C, H, W -> H, W, C\n",
    "    img_numpy = cv2.cvtColor(img_numpy, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"Frame\", img_numpy)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "img_height, img_width = img.shape[:2]\n",
    "spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "adjusted_coords = adjust_spherical_coords(spherical_coords)\n",
    "x, y = spherical_to_equirectangular_coords(adjusted_coords, img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"./data/example/room1/R.png\")\n",
    "img2 = cv2.resize(img , (1024, 512))\n",
    "cv2.imwrite(\"./data/example/room3/R.png\" , img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 画像の読み込み\n",
    "img = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "img = cv2.imread(\"./data/example/room3/O.png\")\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "w_half = int(w / 2)\n",
    "h_half = int(h / 2)\n",
    "\n",
    "# メッシュグリッドの生成\n",
    "phi, theta = np.meshgrid(np.linspace(-np.pi, np.pi, w_half*2),\n",
    "                         np.linspace(-np.pi/2, np.pi/2, h_half*2))\n",
    "\n",
    "\n",
    "# 球面座標\n",
    "x = np.cos(theta) * np.cos(phi)\n",
    "y = np.cos(theta) * np.sin(phi)\n",
    "z = np.sin(theta)\n",
    "\n",
    "# z軸周りにπ/2ラジアン回転\n",
    "rot = np.pi / 2\n",
    "xx = x * np.cos(rot) + z * np.sin(rot)\n",
    "yy = y\n",
    "zz = -x * np.sin(rot) + z * np.cos(rot)\n",
    "\n",
    "# 逆球面座標変換\n",
    "theta = np.arcsin(zz)\n",
    "phi = np.arctan2(yy, xx)\n",
    "\n",
    "# 画像座標へのマッピング\n",
    "Y = 2*theta / np.pi * h_half + h_half\n",
    "X = phi / np.pi * w_half + w_half\n",
    "\n",
    "# 画像のリマッピングと保存\n",
    "out = cv2.remap(img, X.astype(np.float32), Y.astype(np.float32), cv2.INTER_LINEAR, borderMode=cv2.BORDER_WRAP)\n",
    "cv2.imwrite(\"dst.png\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equirectangular_to_spherical_coords(img_width, img_height, device='cpu'):\n",
    "    theta = torch.linspace(0, np.pi, img_height, device=device)  # 0からπ\n",
    "    phi = torch.linspace(0, 2 * np.pi, img_width, device=device)  # 0から2π\n",
    "    phi_grid, theta_grid = torch.meshgrid(phi, theta, indexing=\"xy\")\n",
    "    return torch.stack([theta_grid, phi_grid, torch.ones_like(theta_grid)], dim=-1)\n",
    "\n",
    "def is_in_middle_latitude(img_width, img_height, x, y, device='cpu'):\n",
    "    # 全天球画像の座標から球面座標を取得\n",
    "    spherical_coords = equirectangular_to_spherical_coords(img_width, img_height, device)\n",
    "    \n",
    "    # x, y 座標でのシータの値を取得\n",
    "    theta_at_xy = spherical_coords[y, x, 0]\n",
    "    \n",
    "    # θがπ/4から3π/4の間にあるかチェック\n",
    "    return np.pi/4 <= theta_at_xy < 3*np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "a = is_in_middle_latitude(1024, 512, 0, 0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_to_cartesian(phi, theta):\n",
    "    x = np.cos(theta) * np.cos(phi)\n",
    "    y = np.cos(theta) * np.sin(phi)\n",
    "    z = np.sin(theta)\n",
    "    return x, y, z\n",
    "\n",
    "def rotate_coordinates(x, y, z, angle=np.pi/2):\n",
    "    xx = x * np.cos(angle) + z * np.sin(angle)\n",
    "    yy = y\n",
    "    zz = -x * np.sin(angle) + z * np.cos(angle)\n",
    "    return xx, yy, zz\n",
    "\n",
    "def cartesian_to_spherical(x, y, z):\n",
    "    theta = np.arcsin(z)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return phi, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coordinate(input_xy, image_size_hw):\n",
    "    h, w = image_size_hw\n",
    "    w_half = w / 2\n",
    "    h_half = h / 2\n",
    "    \n",
    "    phi = (input_xy[0] - w_half) * np.pi * 2 /w\n",
    "    theta = (input_xy[1] - h_half) * np.pi /h\n",
    "    \n",
    "    x, y, z = spherical_to_cartesian(phi, theta)\n",
    "    xx, yy, zz = rotate_coordinates(x, y, z)\n",
    "    new_phi, new_theta = cartesian_to_spherical(xx, yy, zz)\n",
    "\n",
    "    new_y = 2*new_theta * h_half / np.pi + h_half\n",
    "    new_x = new_phi * w_half / np.pi + w_half\n",
    "    \n",
    "    return new_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6689710972195777 0.8812047495569755\n",
      "0.6872233929727672 0.07584095748953572\n",
      "(655.6140459704815, 268.3601543918407)\n"
     ]
    }
   ],
   "source": [
    "image_size = (512, 1024) \n",
    "input_coord = (784, 368)\n",
    "result = convert_coordinate(input_coord, image_size)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.141592653589793 -3.141592653589793\n",
      "-1.5707963267948966 0.0\n",
      "(0.0, 256.0)\n",
      "3.141592653589793 2.0344439357957027\n",
      "0.0 1.5707963267948966\n",
      "(843.5628122370218, 512.0)\n"
     ]
    }
   ],
   "source": [
    "# テストケース2: 画像の一端 (0, 0)\n",
    "input_coord = (0, 0)\n",
    "result = convert_coordinate(input_coord, image_size)\n",
    "print(result)\n",
    "# テストケース3: 画像の他の端 (1600, 800)\n",
    "input_coord = (1024, 256)\n",
    "result = convert_coordinate(input_coord, image_size)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./data/data_100/Room/0/O2.png\")\n",
    "\n",
    "# 点の位置\n",
    "position = (784, 368)\n",
    "position = (200, 308)\n",
    "# 点の色（BGR形式）\n",
    "color = (0, 0, 255)  # 緑色\n",
    "\n",
    "# 点を描画\n",
    "cv2.drawMarker(img, position, color, markerType=cv2.MARKER_CROSS, markerSize=40, thickness=2, line_type=cv2.LINE_AA)\n",
    "cv2.imshow('Image with a marker', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9144080232812801 -1.2333506232875153\n",
      "0.3190680038802134 0.3256095949097761\n"
     ]
    }
   ],
   "source": [
    "img2 = cv2.imread(\"./data/data_100/Room/0/O.png\")\n",
    "\n",
    "# 点の位置\n",
    "position2 = convert_coordinate(position, image_size)\n",
    "position2 = (int(position2[0]), int(position2[1]))\n",
    "\n",
    "# 点の色（BGR形式）\n",
    "color = (0, 0, 255)  # 緑色\n",
    "\n",
    "# 点を描画\n",
    "cv2.drawMarker(img2, position2, color, markerType=cv2.MARKER_CROSS, markerSize=40, thickness=2, line_type=cv2.LINE_AA)\n",
    "cv2.imshow('Image with a marker', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 309)\n"
     ]
    }
   ],
   "source": [
    "print(position2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"./O.png\")\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "w_half = int(w / 2)\n",
    "h_half = int(h / 2)\n",
    "\n",
    "# メッシュグリッドの生成\n",
    "phi, theta = np.meshgrid(np.linspace(-np.pi, np.pi, w_half*2),\n",
    "                         np.linspace(-np.pi/2, np.pi/2, h_half*2))\n",
    "\n",
    "\n",
    "# 球面座標\n",
    "x = np.cos(theta) * np.cos(phi)\n",
    "y = np.cos(theta) * np.sin(phi)\n",
    "z = np.sin(theta)\n",
    "\n",
    "# z軸周りにπ/2ラジアン回転\n",
    "rot = np.pi / 2\n",
    "xx = x * np.cos(rot) + z * np.sin(rot)\n",
    "yy = y\n",
    "zz = -x * np.sin(rot) + z * np.cos(rot)\n",
    "\n",
    "# 逆球面座標変換\n",
    "theta = np.arcsin(zz)\n",
    "phi = np.arctan2(yy, xx)\n",
    "\n",
    "# 画像座標へのマッピング\n",
    "Y = 2*theta / np.pi * h_half + h_half\n",
    "X = phi / np.pi * w_half + w_half\n",
    "\n",
    "# 画像のリマッピングと保存\n",
    "out = cv2.remap(img, X.astype(np.float32), Y.astype(np.float32), cv2.INTER_LINEAR, borderMode=cv2.BORDER_WRAP)\n",
    "cv2.imwrite(\"dst.png\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keypoints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
